{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro_markdown"
   },
   "source": [
    "# PRM-Math: Process Reward Model for Mathematical Reasoning\n",
    "\n",
    "This notebook implements a **Process Reward Model (PRM)** using the \"Generative Verifier\" paradigm. It fine-tunes **Qwen-2.5-Math-1.5B-Instruct** to classify intermediate reasoning steps as correct (+) or incorrect (-) in mathematical problem-solving.\n",
    "\n",
    "## Key Features\n",
    "- **Paradigm**: Decoder-Only Generative Verifier\n",
    "- **Base Model**: Qwen/Qwen2.5-Math-1.5B-Instruct (1.5B parameters)\n",
    "- **Training Method**: QLoRA (4-bit quantization) via Unsloth + TRL\n",
    "- **Inference Engine**: Best-of-N search with step-wise verification\n",
    "- **Data Source**: Math-Shepherd dataset\n",
    "\n",
    "---\n",
    "\n",
    "**Important**: Make sure to select a GPU runtime!\n",
    "- Go to `Runtime` \u2192 `Change runtime type` \u2192 Select `T4 GPU` (or better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_gpu_header"
   },
   "source": [
    "## 1. Check GPU and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "check_gpu",
    "outputId": "59839eec-703b-402e-9142-7a86801448c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 10 22:13:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   34C    P8             16W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU: NVIDIA L4\n",
      "GPU Memory: 23.80 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_header"
   },
   "source": [
    "## 2. Install Dependencies\n",
    "\n",
    "**IMPORTANT: Follow these steps carefully!**\n",
    "\n",
    "1. Run the installation cell below\n",
    "2. **Restart the runtime**: `Runtime` \u2192 `Restart runtime`\n",
    "3. After restart, **skip the installation cell** and continue from \"Verify installations\"\n",
    "\n",
    "This is required because NumPy needs to be downgraded and the runtime must reload the correct version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "install_deps",
    "outputId": "79c29260-501a-49ac-c2b6-65ec6d0a2508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n",
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "3307ba28f28e47faa1e4f1cc32b92944",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-n2_48v03/unsloth_27f0b89e3c2d4769a186b0f0d24535bd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-n2_48v03/unsloth_27f0b89e3c2d4769a186b0f0d24535bd\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit aa063de198f44822b2a7e7d0d9b97a4bc5e705c7\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting unsloth_zoo>=2025.12.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading unsloth_zoo-2025.12.3-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n",
      "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading tyro-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.57.3)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.29.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
      "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.12.0)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.18.0)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.12.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.3)\n",
      "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.12.3-py3-none-any.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m288.6/288.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-1.0.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for unsloth: filename=unsloth-2025.12.4-py3-none-any.whl size=378593 sha256=d5654e7938951e554b6ddfff04afe860e3892a20939abe042d22d0fac9d142a9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-460lu214/wheels/60/3e/1f/e576c07051d90cf64b6a41434d87ccf4db33fafd5343bf5de0\n",
      "Successfully built unsloth\n",
      "Installing collected packages: torchao, unsloth, pyarrow, msgspec, tyro, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n",
      "  Attempting uninstall: torchao\n",
      "    Found existing installation: torchao 0.10.0\n",
      "    Uninstalling torchao-0.10.0:\n",
      "      Successfully uninstalled torchao-0.10.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "Successfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.20.0 pyarrow-22.0.0 torchao-0.14.1 trl-0.24.0 tyro-1.0.0 unsloth-2025.12.4 unsloth_zoo-2025.12.3\n",
      "\n",
      "============================================================\n",
      "IMPORTANT: Now restart the runtime!\n",
      "Go to: Runtime -> Restart runtime\n",
      "Then skip this cell and run the next cells.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Run this cell, then restart runtime (Runtime -> Restart runtime)\n",
    "# After restart, skip this cell and continue from the next one\n",
    "\n",
    "# First, fix NumPy version (must be done before other installs)\n",
    "!pip uninstall numpy -y\n",
    "!pip install \"numpy<2.0.0\"\n",
    "\n",
    "# Install Unsloth for Colab (handles CUDA compatibility automatically)\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "# Install other dependencies\n",
    "!pip install transformers>=4.36.0 datasets>=2.14.0 accelerate>=0.25.0\n",
    "!pip install trl>=0.7.0 peft>=0.7.0 bitsandbytes>=0.41.0\n",
    "!pip install pyyaml>=6.0 tqdm>=4.66.0\n",
    "\n",
    "# Note: Skipping vLLM as it can cause conflicts. Using transformers for inference instead.\n",
    "# !pip install vllm>=0.2.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPORTANT: Now restart the runtime!\")\n",
    "print(\"Go to: Runtime -> Restart runtime\")\n",
    "print(\"Then skip this cell and run the next cells.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "verify_install",
    "outputId": "a6ca528c-6eb1-452d-95bb-70198ddae5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1050536483.py:15: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastLanguageModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/unsloth/models/rl_replacements.py:946: UserWarning: You are importing from 'trl.experimental'. APIs here are unstable and may change or be removed without notice. Silence this warning by setting environment variable TRL_EXPERIMENTAL_SILENCE=1.\n",
      "  import trl.experimental.openenv.utils as openenv_utils\n",
      "WARNING:unsloth_zoo.log:Unsloth: Failed to import trl openenv: No module named 'trl.experimental.openenv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers: 4.57.3\n",
      "Datasets: 4.3.0\n",
      "PEFT: 0.18.0\n",
      "TRL: 0.24.0\n",
      "Unsloth: Installed successfully!\n",
      "\n",
      "\u2713 All dependencies verified!\n"
     ]
    }
   ],
   "source": [
    "# Verify installations (run this AFTER restarting runtime)\n",
    "import numpy as np\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Check NumPy version\n",
    "if np.__version__.startswith(\"2\"):\n",
    "    print(\"\\n\u26a0\ufe0f  WARNING: NumPy 2.x detected!\")\n",
    "    print(\"Please run the installation cell above, then restart runtime.\")\n",
    "    raise RuntimeError(\"NumPy version must be < 2.0.0\")\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import peft\n",
    "import trl\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "print(f\"Datasets: {datasets.__version__}\")\n",
    "print(f\"PEFT: {peft.__version__}\")\n",
    "print(f\"TRL: {trl.__version__}\")\n",
    "print(\"Unsloth: Installed successfully!\")\n",
    "print(\"\\n\u2713 All dependencies verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_header"
   },
   "source": "## 3. Mount Google Drive & Configuration\n\nMount Google Drive for persistent storage of checkpoints and models."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "config",
    "outputId": "75a71e7f-ea0c-439c-e0df-4d7def050ebd"
   },
   "outputs": [],
   "source": "# Mount Google Drive for persistent storage\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Create project directory in Google Drive\nimport os\nDRIVE_PROJECT_PATH = \"/content/drive/MyDrive/Colab Notebooks/PRM-Math\"\nos.makedirs(DRIVE_PROJECT_PATH, exist_ok=True)\nos.makedirs(f\"{DRIVE_PROJECT_PATH}/checkpoints\", exist_ok=True)\nos.makedirs(f\"{DRIVE_PROJECT_PATH}/logs\", exist_ok=True)\n\nprint(f\"Google Drive mounted!\")\nprint(f\"Project path: {DRIVE_PROJECT_PATH}\")\n\n# Check for existing checkpoints (for resume training)\ncheckpoint_dir = f\"{DRIVE_PROJECT_PATH}/checkpoints\"\nexisting_checkpoints = []\nif os.path.exists(checkpoint_dir):\n    for item in os.listdir(checkpoint_dir):\n        item_path = os.path.join(checkpoint_dir, item)\n        if os.path.isdir(item_path) and item.startswith(\"checkpoint-\"):\n            existing_checkpoints.append(item_path)\n    existing_checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n\nif existing_checkpoints:\n    print(f\"\\nFound {len(existing_checkpoints)} existing checkpoint(s):\")\n    for cp in existing_checkpoints[-3:]:  # Show last 3\n        print(f\"  - {cp}\")\n    print(f\"\\nLatest: {existing_checkpoints[-1]}\")\n    RESUME_FROM_CHECKPOINT = existing_checkpoints[-1]\nelse:\n    print(\"\\nNo existing checkpoints found. Will start fresh training.\")\n    RESUME_FROM_CHECKPOINT = None\n\n# Check for existing merged model\nmerged_model_path = f\"{DRIVE_PROJECT_PATH}/checkpoints/merged_model\"\nif os.path.exists(merged_model_path):\n    print(f\"\\nFound existing merged model at: {merged_model_path}\")\n    print(\"You can skip training and go directly to evaluation.\")"
  },
  {
   "cell_type": "code",
   "source": "# Configuration - using Google Drive paths for persistence\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional\n\n@dataclass\nclass Config:\n    # Project settings\n    project_name: str = \"qwen-prm-math\"\n    seed: int = 42\n    output_dir: str = f\"{DRIVE_PROJECT_PATH}/checkpoints\"  # Save to Google Drive\n    logging_dir: str = f\"{DRIVE_PROJECT_PATH}/logs\"\n\n    # Data settings\n    dataset_name: str = \"peiyi9979/Math-Shepherd\"\n    max_samples: int = 30000  # Adjust based on time/memory\n    balance_positives: bool = True\n    validation_split: float = 0.1\n\n    # Model settings - 1.5B model\n    base_model: str = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"\n    max_seq_length: int = 2048\n    load_in_4bit: bool = True\n\n    # LoRA settings\n    lora_r: int = 16\n    lora_alpha: int = 16\n    lora_dropout: float = 0.05\n    target_modules: List[str] = field(default_factory=lambda: [\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n        \"gate_proj\", \"up_proj\", \"down_proj\"\n    ])\n\n    # Training settings\n    batch_size: int = 8  # For L4 GPU with 1.5B model\n    gradient_accumulation_steps: int = 4\n    learning_rate: float = 1e-4\n    num_train_epochs: int = 3\n    warmup_ratio: float = 0.03\n    save_steps: int = 100  # Save checkpoint every 100 steps\n    logging_steps: int = 10\n    response_template: str = \"<|verify|>\"\n    \n    # Resume training\n    resume_from_checkpoint: str = RESUME_FROM_CHECKPOINT  # Auto-detected above\n\n    # Inference settings\n    n_candidates: int = 16\n    temperature: float = 0.7\n    max_new_tokens: int = 512\n\n# Create config instance\nconfig = Config()\n\nprint(\"Configuration loaded!\")\nprint(f\"  Base model: {config.base_model}\")\nprint(f\"  Max samples: {config.max_samples}\")\nprint(f\"  Batch size: {config.batch_size}\")\nprint(f\"  Learning rate: {config.learning_rate}\")\nprint(f\"  Output dir: {config.output_dir}\")\nif config.resume_from_checkpoint:\n    print(f\"  Resume from: {config.resume_from_checkpoint}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_header"
   },
   "source": [
    "## 4. Load and Process Dataset\n",
    "\n",
    "Load the Math-Shepherd dataset and process it for PRM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 883,
     "referenced_widgets": [
      "87cf338bd8fd423494f1f9cd3ed21a84",
      "c03a6f3024684cadaaf71169888772a8",
      "ef95aba74c4643ea9245f4e52141ffbd",
      "a1523c3b8f9f4c54a59c1644a1f9e9c0",
      "20d52e704309459a9ffbe80f3e9ee207",
      "13968d9e5c0141178b61b0791fda3944",
      "fcf91a6b8e6f434e907c6af76df71777",
      "e108630cdaf046d9b6a59c3096d748e0",
      "8d10b0f4287148c997a5861bfc022fa9",
      "8ac85a27544549deb4cd67e9f14358fa",
      "ef7e4dff023d44ddbfb7cf9dcd8592cd",
      "5921a0afc2e64509af04131151929d32",
      "6836ed15891543f6840f452c15811cc2",
      "970d6cccfd9446fa8a518cf71250b21b",
      "d1155c55e42240cea85df02a949a84f1",
      "f16bc2510d664a5697c76a61472201bf",
      "27c41d6ca8ef438ebb928eb2c1047879",
      "a34fecb1301543178113856bd391fe27",
      "23d56bc5a429447ebe228c511bb6367b",
      "d5601c851a80467391ffd7073e9826a2",
      "633c8fcd3f2d4e4390bb1e6d59e78a55",
      "5907dbda3ca94a399455aabb0f1a2ff9",
      "887922900a5d43e3bacf76e2bac5ed07",
      "836f44328fe641c1904d061d8b169630",
      "30669924477442aab4a0a0521e1038c1",
      "a710783e706948c7bcefbb929ab402c1",
      "2f0bae426e9f45f794828f41e1e43713",
      "a284cadba47b4bfaa036cc9e23dff744",
      "fb36005415af467b835ba243f21ad820",
      "3f7395d38bcf417fbb6cacd480369912",
      "02a63cc79e6e41f6ad77813763360a28",
      "e4740d9cfc6e443eb8b0a014de778192",
      "4da9effb5db54668b5dc2b67573767d6"
     ]
    },
    "id": "load_dataset",
    "outputId": "7562d840-e290-49e6-a351-4a7bf2b9cfd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Math-Shepherd dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cf338bd8fd423494f1f9cd3ed21a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5921a0afc2e64509af04131151929d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "math-shepherd.jsonl:   0%|          | 0.00/793M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887922900a5d43e3bacf76e2bac5ed07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/444655 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 444655 examples\n",
      "\n",
      "==================================================\n",
      "Dataset columns: ['input', 'label', 'task']\n",
      "==================================================\n",
      "\n",
      "Sample item (label field - last 200 chars):\n",
      "'sons per week. +\\nStep 4: Janet spends 120 + 140 = <<120+140=260>>260 on music lessons per week. +\\nStep 5: She spends 260 * 52 = <<260*52=13520>>13520 on music lessons in a year. The answer is: 13520 -'\n",
      "==================================================\n",
      "\n",
      "Processing dataset into PRM format...\n",
      "\n",
      "Test parsing first item: 5 steps found\n",
      "  First step: Step 1: Janet spends 3 hours + 5 hours = <<3+5=8>>8 hours per week on music less... [+]\n",
      "\n",
      "Could not parse item 926:\n",
      "  Label (last 200 chars): \"y dollars did Jerusha earn? Use L to represent Lottie's earnings. Jerusha earned 4L. +\\nJerusha and Lottie earned 4L+85=<<4L+85=99>>99 together. +\\nJerusha earned 99-L=<<99-L=85>>85. The answer is: 85 -\"\n",
      "\n",
      "Parsing results:\n",
      "  Successfully parsed: 7988 items\n",
      "  Failed to parse: 1 items\n",
      "  Total step-level examples: 30001\n",
      "\n",
      "Label distribution:\n",
      "  Positive examples: 8683\n",
      "  Negative examples: 21318\n",
      "  Balanced to: 15000 examples\n",
      "\n",
      "Final dataset:\n",
      "  Training: 13500 examples\n",
      "  Validation: 1500 examples\n",
      "\n",
      "==================================================\n",
      "Sample training example:\n",
      "==================================================\n",
      "Problem: Kevin has a shoebox filled with toads.  Every day, Kevin feeds each toad 3 worms.  It takes Kevin 15 minutes to find each worm.  If it takes Kevin 6 hours to find enough worms to feed all of his toads, how many toads does Kevin have in his shoebox?\n",
      "\n",
      "Solution:\n",
      "Step 1: Kevin has to find 3*N worms where N is the number of toads, or 3*N=6 where N=6/3\n",
      "Step 2: Solving for N, we get N=6/3 toads\n",
      "<|verify|> +\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "from typing import Dict, Any, List\n",
    "import random\n",
    "\n",
    "print(\"Loading Math-Shepherd dataset...\")\n",
    "raw_dataset = load_dataset(config.dataset_name, split=\"train\")\n",
    "print(f\"Loaded {len(raw_dataset)} examples\")\n",
    "\n",
    "# Inspect the dataset format\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Dataset columns:\", raw_dataset.column_names)\n",
    "print(\"=\"*50)\n",
    "print(\"\\nSample item (label field - last 200 chars):\")\n",
    "sample = raw_dataset[0]\n",
    "print(repr(sample['label'][-200:]))\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "def parse_math_shepherd_item(item: Dict) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Parse Math-Shepherd dataset format.\n",
    "\n",
    "    The 'label' field contains: \"Problem text Step 1: ... +\\nStep 2: ... -\\n...\"\n",
    "    Each step ends with a space and +/- label.\n",
    "    \"\"\"\n",
    "    label_text = item.get(\"label\", \"\")\n",
    "    if not label_text:\n",
    "        return []\n",
    "\n",
    "    # Find where Step 1 starts to separate problem from steps\n",
    "    step1_match = re.search(r'Step\\s*1\\s*[:\\.]', label_text)\n",
    "    if not step1_match:\n",
    "        return []\n",
    "\n",
    "    problem = label_text[:step1_match.start()].strip()\n",
    "    steps_text = label_text[step1_match.start():]\n",
    "\n",
    "    if not problem:\n",
    "        return []\n",
    "\n",
    "    # Parse steps using regex to find \"Step N: content +/-\"\n",
    "    # The pattern captures: step header, content, and label\n",
    "    step_pattern = r'(Step\\s*\\d+\\s*[:\\.])\\s*(.+?)\\s+([+-])(?=\\s*Step\\s*\\d+|\\s*$)'\n",
    "    matches = re.findall(step_pattern, steps_text, re.DOTALL)\n",
    "\n",
    "    if not matches:\n",
    "        # Try alternative: split by newlines and look for +/- at end\n",
    "        lines = steps_text.strip().split('\\n')\n",
    "        steps = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Check for \" +\" or \" -\" at the end\n",
    "            match = re.match(r'(.+?)\\s+([+-])\\s*$', line)\n",
    "            if match:\n",
    "                steps.append({\"text\": match.group(1).strip(), \"label\": match.group(2)})\n",
    "\n",
    "        if not steps:\n",
    "            return []\n",
    "    else:\n",
    "        steps = []\n",
    "        for header, content, label in matches:\n",
    "            step_text = f\"{header} {content}\".strip()\n",
    "            steps.append({\"text\": step_text, \"label\": label})\n",
    "\n",
    "    if not steps:\n",
    "        return []\n",
    "\n",
    "    # Create training examples with cumulative context\n",
    "    examples = []\n",
    "    context = f\"Problem: {problem}\\n\\nSolution:\"\n",
    "\n",
    "    for step in steps:\n",
    "        example = {\n",
    "            \"context\": context,\n",
    "            \"step\": step[\"text\"],\n",
    "            \"label\": step[\"label\"]\n",
    "        }\n",
    "        examples.append(example)\n",
    "        context = f\"{context}\\n{step['text']}\"\n",
    "\n",
    "    return examples\n",
    "\n",
    "\n",
    "def format_for_training(example: Dict[str, Any], response_template: str) -> str:\n",
    "    \"\"\"Format example for generative verifier training.\"\"\"\n",
    "    text = f\"{example['context']}\\n{example['step']}\\n{response_template} {example['label']}\"\n",
    "    return text\n",
    "\n",
    "\n",
    "# Process dataset\n",
    "print(\"\\nProcessing dataset into PRM format...\")\n",
    "all_examples = []\n",
    "parsed_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "# Test parsing on first item\n",
    "test_result = parse_math_shepherd_item(raw_dataset[0])\n",
    "print(f\"\\nTest parsing first item: {len(test_result)} steps found\")\n",
    "if test_result:\n",
    "    print(f\"  First step: {test_result[0]['step'][:80]}... [{test_result[0]['label']}]\")\n",
    "\n",
    "for i, item in enumerate(raw_dataset):\n",
    "    if len(all_examples) >= config.max_samples * 2:\n",
    "        break\n",
    "\n",
    "    examples = parse_math_shepherd_item(item)\n",
    "\n",
    "    if examples:\n",
    "        all_examples.extend(examples)\n",
    "        parsed_count += 1\n",
    "    else:\n",
    "        failed_count += 1\n",
    "        if failed_count <= 2:\n",
    "            print(f\"\\nCould not parse item {i}:\")\n",
    "            print(f\"  Label (last 200 chars): {repr(item.get('label', 'N/A')[-200:])}\")\n",
    "\n",
    "print(f\"\\nParsing results:\")\n",
    "print(f\"  Successfully parsed: {parsed_count} items\")\n",
    "print(f\"  Failed to parse: {failed_count} items\")\n",
    "print(f\"  Total step-level examples: {len(all_examples)}\")\n",
    "\n",
    "if len(all_examples) == 0:\n",
    "    raise ValueError(\"Could not create any training examples. Please check the dataset format.\")\n",
    "\n",
    "# Balance positive and negative examples\n",
    "positives = [ex for ex in all_examples if ex[\"label\"] == \"+\"]\n",
    "negatives = [ex for ex in all_examples if ex[\"label\"] == \"-\"]\n",
    "\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(f\"  Positive examples: {len(positives)}\")\n",
    "print(f\"  Negative examples: {len(negatives)}\")\n",
    "\n",
    "if config.balance_positives and len(negatives) > 0 and len(positives) > 0:\n",
    "    min_count = min(len(positives), len(negatives), config.max_samples // 2)\n",
    "    random.seed(config.seed)\n",
    "    balanced_examples = (\n",
    "        random.sample(positives, min_count) +\n",
    "        random.sample(negatives, min_count)\n",
    "    )\n",
    "    random.shuffle(balanced_examples)\n",
    "    all_examples = balanced_examples\n",
    "    print(f\"  Balanced to: {len(all_examples)} examples\")\n",
    "else:\n",
    "    random.seed(config.seed)\n",
    "    random.shuffle(all_examples)\n",
    "    all_examples = all_examples[:config.max_samples]\n",
    "    print(f\"  Limited to: {len(all_examples)} examples\")\n",
    "\n",
    "# Format for training\n",
    "formatted_texts = [\n",
    "    format_for_training(ex, config.response_template)\n",
    "    for ex in all_examples\n",
    "]\n",
    "\n",
    "# Create HuggingFace dataset\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict({\"text\": formatted_texts})\n",
    "\n",
    "# Train/validation split\n",
    "split_dataset = train_dataset.train_test_split(\n",
    "    test_size=config.validation_split,\n",
    "    seed=config.seed\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal dataset:\")\n",
    "print(f\"  Training: {len(split_dataset['train'])} examples\")\n",
    "print(f\"  Validation: {len(split_dataset['test'])} examples\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Sample training example:\")\n",
    "print(\"=\"*50)\n",
    "sample_text = formatted_texts[0]\n",
    "print(sample_text[:800] + \"...\" if len(sample_text) > 800 else sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_header"
   },
   "source": [
    "## 5. Load Model with Unsloth\n",
    "\n",
    "Load the base model with 4-bit quantization and add LoRA adapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612,
     "referenced_widgets": [
      "21421d5313de46feb571bbbdb92c91a7",
      "4d31b6225af14914a4d1b4a0921a797f",
      "ffa952b2dc1a4d4eb9bec3a03d83418d",
      "23ef1c5a42094366b66f6b807e3b6d2c",
      "6a60551fe0d44f4e8e288b6fcd2e8f0b",
      "7fb93e1f4fc5482f8e9a60d1b24a3e43",
      "515aa26bbd9b420ea98bba7978162d1d",
      "1165e8baa84e41519093e5d6957306d7",
      "a8324ce1713a40cd9ad046af10c13115",
      "1084ee12990c49419215fc020ae2b893",
      "32fdef866d314881b6449364f7eea3fc",
      "470df68d008249368f881258c4344018",
      "432ddd9532e5486db253d3db8a770b68",
      "b5adb245ca2a4839a0d84afd4e98f2b7",
      "c4ec85ca897745888224a8fc6eaa3b5a",
      "c5168ec7996b4e208a3393284c1e7436",
      "ca07e786abca4a8e9a2c01ec09f9e6a3",
      "bca9046b2be04c369ce271b6ce8f765b",
      "254cd26e88c04f6fb36ab9ed47cbdf35",
      "ec5955a2a6bf4197a3cb585314579493",
      "b2190d332aea4978a63ba88527e3752e",
      "a2de85977af644e0ac580ec25f6a160a",
      "de5761c4afe642bb9a5cae7ee26effdf",
      "c34e999df3de46daa12498efc705b1e2",
      "6e38b38e3c384bc5abbfbb55d26856ca",
      "63a8725c4148435cb9cc828bc7159c69",
      "1bac97c71718446f8e030ac6fb1dc435",
      "4012d18f19f548a3b64b26e72b32a332",
      "319c88d1506545ceb3d5d7f04482da43",
      "6dcccf8c5aac4adcba7b81c2c4b531ce",
      "f18fe8558a6a4da188c7b119ce396ea9",
      "744b86adf7d2484dbc53dc112ba02c09",
      "5470afc5235645008f61a029550afaf5",
      "0c8d77105e2740f5a509fd0821da87ed",
      "86fd00c7009a482ea291e19daa9e7983",
      "33a6169a4c4e42bc9930660933a48424",
      "97da26d3187f4683ba850cea6ce0f000",
      "f847c5a7a22240d084a7a3d7ee633bda",
      "cbb07acc3a43421687514e459360ad37",
      "5388126c6d7640619dfcb49dd9c321f8",
      "ae771ba3cc2940dca6981f355e377ff0",
      "12a32595a43e4d90931f62294ca7defd",
      "1f491d1e5f714518b3e45d93efff4401",
      "61a4b3dc1e694aa38e88c9e406edd666",
      "f64f6ee19fd24ea3b71f90e2174973f2",
      "4e5445733c6e4fa99e06d7fefc35b017",
      "f9193f5e203c406ba0aea3598555cd2c",
      "0527f24176ab42d790e7105109ef8e32",
      "4fa458db586048eeb4ae1d0978632ea1",
      "d58e5f71e895482f8bf99e03e9b7a489",
      "dfb161b4d6824280a9c01631b2896d6a",
      "d7cabf5f4f224147a5e16bab2a64e795",
      "46d1b2948aa14d999653f2803da64da2",
      "dc77671a445044eab701fadd7a028981",
      "5a540b2ee84246baa0d5f58471258de0",
      "bf3ebe52f38e460dae32b90f6024f534",
      "265fa99315d74861a7fcc0c0d9eb4213",
      "f9c2736113ce4023a05d95c7a3303048",
      "32ccbc7fd996407dad26506f624cbf7a",
      "376e2d1621bc492893032eaea69defd5",
      "88e636f6386b4175a66589e060b8af7e",
      "6f6ecf4ed3cd410f956118e04e225009",
      "c7ba0df54bb84784a0f92b74c93e5ad4",
      "3fe87f5bf39240969bbd491957549b0b",
      "fc28eb3401df4f8a98fa1679f631b0c5",
      "8ed0fd2512634b9e9a8add62baf536aa",
      "92c875504ff74899944a8e5d666b103b",
      "3bc092665828468d8fa06c0188a67732",
      "153a8abe296243ceae4b24862a93d62f",
      "17c29a5140d04975b721a309232c6ed9",
      "69ff86bcae0a4e788690a3c3c6c36337",
      "c277e5b557d04774b1c288b749f2a563",
      "45659833a4894e6c9f0652c69917fd82",
      "07f635d56d9f40d5b4dfa5b41e418e5e",
      "74eeef45205c408395a739e11ba9d36b",
      "fe6584b1e8474a61b29f2677508d94ec",
      "14186acb1c4642598faaea25aba06b7c",
      "239100f96fdb416eab16e6899edd84b1",
      "1e78aa49bb0e40b68ad0b25b48e5438e",
      "0db02d60fe354a889921ba239078b0b0",
      "defb9657d1ae4956abe594c1014c1b45",
      "23ef73a7638a4acca00dd278c5f28b8a",
      "469bd98623094b3bb81473e8e363cde5",
      "c8f839a3bd664cfab1b94055b78090dc",
      "a53f5fe3a07042fa8cf7a195e0dd60e3",
      "911ed424559c40009540e3668b8c68ba",
      "2eb89fae30ba45b3a350f476aec79904",
      "7876f915aea84c6d8087a3aa3af31a05"
     ]
    },
    "id": "load_model",
    "outputId": "d98d1b88-95b2-4e70-e161-488fa5e6e088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen2.5-Math-1.5B-Instruct\n",
      "This may take a few minutes...\n",
      "\n",
      "==((====))==  Unsloth 2025.12.4: Fast Qwen2 patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21421d5313de46feb571bbbdb92c91a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470df68d008249368f881258c4344018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/161 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5761c4afe642bb9a5cae7ee26effdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8d77105e2740f5a509fd0821da87ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64f6ee19fd24ea3b71f90e2174973f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3ebe52f38e460dae32b90f6024f534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c875504ff74899944a8e5d666b103b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239100f96fdb416eab16e6899edd84b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "  Parameters: 1,543,714,304\n",
      "  Max sequence length: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.12.4 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LoRA adapters added!\n",
      "  LoRA rank: 16\n",
      "  Target modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "print(f\"Loading model: {config.base_model}\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Load model with Unsloth (handles 4-bit quantization automatically)\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=config.base_model,\n",
    "    max_seq_length=config.max_seq_length,\n",
    "    dtype=None,  # Auto-detect\n",
    "    load_in_4bit=config.load_in_4bit,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded!\")\n",
    "print(f\"  Parameters: {model.num_parameters():,}\")\n",
    "print(f\"  Max sequence length: {config.max_seq_length}\")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=config.lora_r,\n",
    "    target_modules=config.target_modules,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=config.seed,\n",
    ")\n",
    "\n",
    "# Ensure padding token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"\\nLoRA adapters added!\")\n",
    "print(f\"  LoRA rank: {config.lora_r}\")\n",
    "print(f\"  Target modules: {config.target_modules}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_header"
   },
   "source": [
    "## 6. Training\n",
    "\n",
    "Fine-tune the model using TRL's SFTTrainer with completion-only loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import trl\n",
    "import torch\n",
    "\n",
    "print(f\"TRL version: {trl.__version__}\")\n",
    "\n",
    "# Fix Unsloth + TRL 0.24 compatibility issue\n",
    "try:\n",
    "    import unsloth.trainer\n",
    "    if not hasattr(unsloth.trainer, 'PADDING_FREE_BLOCKLIST'):\n",
    "        unsloth.trainer.PADDING_FREE_BLOCKLIST = []\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Custom data collator that only computes loss on tokens after <|verify|>\n",
    "class DataCollatorForCompletionOnlyLM:\n",
    "    \"\"\"\n",
    "    Custom collator that masks labels before the response template.\n",
    "    Only computes loss on tokens after the response template.\n",
    "    \"\"\"\n",
    "    def __init__(self, response_template, tokenizer):\n",
    "        self.response_template = response_template  # List of token IDs\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        # Tokenize if needed\n",
    "        if isinstance(examples[0], dict) and \"text\" in examples[0]:\n",
    "            texts = [ex[\"text\"] for ex in examples]\n",
    "            batch = self.tokenizer(\n",
    "                texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=2048,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        else:\n",
    "            batch = self.tokenizer.pad(examples, return_tensors=\"pt\")\n",
    "\n",
    "        # Create labels (copy of input_ids)\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "\n",
    "        # Mask everything before response template\n",
    "        for i, input_ids in enumerate(batch[\"input_ids\"]):\n",
    "            input_list = input_ids.tolist()\n",
    "            response_start = None\n",
    "\n",
    "            # Find where response template starts\n",
    "            template_len = len(self.response_template)\n",
    "            for j in range(len(input_list) - template_len + 1):\n",
    "                if input_list[j:j + template_len] == self.response_template:\n",
    "                    response_start = j + template_len\n",
    "                    break\n",
    "\n",
    "            if response_start is not None:\n",
    "                # Mask everything before and including the template\n",
    "                labels[i, :response_start] = -100\n",
    "            else:\n",
    "                # If template not found, mask everything (no loss)\n",
    "                labels[i, :] = -100\n",
    "\n",
    "        # Also mask padding tokens\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "# Get response template token IDs\n",
    "response_template_ids = tokenizer.encode(\n",
    "    config.response_template,\n",
    "    add_special_tokens=False\n",
    ")\n",
    "print(f\"Response template token IDs: {response_template_ids}\")\n",
    "\n",
    "# Create collator\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template_ids,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config.output_dir,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    num_train_epochs=config.num_train_epochs,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=config.logging_steps,\n",
    "    save_steps=config.save_steps,\n",
    "    save_total_limit=3,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    optim=\"adamw_8bit\",\n",
    "    seed=config.seed,\n",
    "    report_to=\"none\",  # Disable wandb/tensorboard in Colab\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    data_collator=collator,\n",
    "    args=training_args,\n",
    "    max_seq_length=config.max_seq_length,\n",
    ")\n",
    "\n",
    "print(\"\n",
    "Trainer configured!\")\n",
    "print(f\"  Effective batch size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "print(f\"  Training examples: {len(split_dataset['train'])}\")\n",
    "print(f\"  Steps per epoch: {len(split_dataset['train']) // (config.batch_size * config.gradient_accumulation_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206,
     "referenced_widgets": [
      "7f5093dcadf447caa4c5cd5f6ea6d64e",
      "aeeccfd6beae4e69b1e0cce4fab2b196",
      "051325ce4bf84d1495c84fa915f6412e",
      "60c7d67218084e2e8f9781625546c0e9",
      "9efdc30d7ddb41ef84bbcd29878254ac",
      "5c405fea068641e68f749628b3d62a5e",
      "5fff16ff3ce04db8a115ae67aa85cd5b",
      "82a1b717b625443abe29af39247d7325",
      "d5040371193b44ddb6218d5a0376280d",
      "cd95bbf703184a95a7b3bd77815a8bdd",
      "756ceab403c048f18587a491d878016f",
      "550e85f8021e4b168bbe8a0856154720",
      "e589849d5ac84675acd25aedcfadf56b",
      "ee6a7b4a2c4b4b14a6ccefeaac814c46",
      "43445d194e97489ba125f46a54d45b3d",
      "cf4cbe0252af48069a770a0735b66b5f",
      "df2af4741c374ff5819d358246dfe4fe",
      "ee4d7b2694c047e49550af84992095e4",
      "7b96cb5199804972aefa1d510aeddfe5",
      "a83eaa27285647d18afd4cdd43ef7f9d",
      "4a20ad5a6ffe481bad79ba267dc0b01a",
      "3e363047a9d040eebfcdb47704bbd8d3"
     ]
    },
    "id": "setup_trainer",
    "outputId": "4545b12d-8b32-4fe5-d6a2-5fe67f0dc88b"
   },
   "outputs": [],
   "source": "# Start training (with resume support)\n\n# Check that trainer is defined (from previous cell)\nif 'trainer' not in dir():\n    raise NameError(\n        \"trainer is not defined!\\n\"\n        \"Please run the previous cell (Trainer Configuration) first.\\n\"\n        \"Make sure to run cells in order: Config \u2192 Dataset \u2192 Model \u2192 Trainer \u2192 Train\"\n    )\n\nprint(\"Starting training...\")\nprint(\"=\"*50)\n\nif config.resume_from_checkpoint:\n    print(f\"Resuming from checkpoint: {config.resume_from_checkpoint}\")\n    trainer_stats = trainer.train(resume_from_checkpoint=config.resume_from_checkpoint)\nelse:\n    print(\"Starting fresh training...\")\n    trainer_stats = trainer.train()\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Training complete!\")\nprint(f\"  Total steps: {trainer_stats.global_step}\")\nprint(f\"  Final loss: {trainer_stats.training_loss:.4f}\")\nprint(f\"  Checkpoints saved to: {config.output_dir}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "train",
    "outputId": "72291305-f3cc-4353-f645-c92835aa015e"
   },
   "outputs": [],
   "source": "# Save the merged model to Google Drive\nmerged_model_path = f\"{config.output_dir}/merged_model\"\n\nprint(f\"Saving merged model to {merged_model_path}...\")\nprint(\"(This saves directly to Google Drive for persistence)\")\n\n# Save in 16-bit for inference\nmodel.save_pretrained_merged(\n    merged_model_path,\n    tokenizer,\n    save_method=\"merged_16bit\",\n)\n\nprint(\"\\nModel saved successfully!\")\nprint(f\"Location: {merged_model_path}\")\nprint(\"\\nYou can now:\")\nprint(\"1. Restart runtime for evaluation\")\nprint(\"2. Or disconnect and reconnect later - your model is saved!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "95282053a87f492898c6c7252d1f1ada",
      "9b94a65d13e841259d59931e5c6515ab",
      "886b5e7e8b9b4276bd268523763ad21b",
      "420190dc4dd545f5a0c2f56a79b0b72a",
      "330ec35c7c1346af9885a8beb8ebdece",
      "ad0163b617aa422cb0c5be6bb9ccd480",
      "98bc502171994974b667740779cdb709",
      "ddceca5cc97744329ebfd440415cff8b",
      "192fb806959741298d9698389b75b6ba",
      "008bced0cf5c45e8a86d9575372d6e1c",
      "496a7f680f5742dd90648c6a227ceb22",
      "70744076965f47df9a4dde198dbdc998",
      "0d568da2ef4f45d1ad2c2390870639bc",
      "a1af39e8754440afb784e6ed589fdc88",
      "1f4bec4c01b44c02aa0d3a6413d1491a",
      "686b0c2e41f543efb1ba0db1f7cc7645",
      "0d758e03caaa42ed84ac279fb0dddc98",
      "6e8842ba145b4201acd49634d00b716a",
      "6aafc9587caf41bba39d9a9467d2ab65",
      "1f43919678b741b7947b7c45de1eacbd",
      "e230987a642e4f48b1c9d92232ddcf52",
      "8b07f697596241d7a0a1e5044f7f39a6"
     ]
    },
    "id": "save_model",
    "outputId": "918b94bd-72d0-4d72-8b94-e901ab705777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving merged model to ./checkpoints/merged_model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95282053a87f492898c6c7252d1f1ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rUnsloth: Preparing safetensor model files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70744076965f47df9a4dde198dbdc998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:10<00:00, 10.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:10<00:00, 10.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/content/checkpoints/merged_model`\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "merged_model_path = f\"{config.output_dir}/merged_model\"\n",
    "\n",
    "print(f\"Saving merged model to {merged_model_path}...\")\n",
    "\n",
    "# Save in 16-bit for inference\n",
    "model.save_pretrained_merged(\n",
    "    merged_model_path,\n",
    "    tokenizer,\n",
    "    save_method=\"merged_16bit\",\n",
    ")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference_header"
   },
   "source": [
    "## 7. Inference: Best-of-N with PRM Scoring\n",
    "\n",
    "Use the trained PRM to score and rank multiple solution candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "verifier_class",
    "outputId": "4f1ca524-2b43-48ec-eaa6-dcec8e9eabcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model for inference...\n",
      "Verifier initialized!\n",
      "  + token ID: 10\n",
      "  - token ID: 12\n",
      "\n",
      "Verifier ready!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# First, prepare the trained model for inference\n",
    "print(\"Preparing model for inference...\")\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "class PRMVerifier:\n",
    "    \"\"\"\n",
    "    Process Reward Model verifier for scoring mathematical reasoning steps.\n",
    "    Uses the trained Unsloth model in inference mode.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, device: str = \"cuda\"):\n",
    "        self.device = device\n",
    "        self.response_template = config.response_template\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # Get token IDs for + and -\n",
    "        self.pos_token_id = self.tokenizer.encode(\"+\", add_special_tokens=False)[0]\n",
    "        self.neg_token_id = self.tokenizer.encode(\"-\", add_special_tokens=False)[0]\n",
    "\n",
    "        print(\"Verifier initialized!\")\n",
    "        print(f\"  + token ID: {self.pos_token_id}\")\n",
    "        print(f\"  - token ID: {self.neg_token_id}\")\n",
    "\n",
    "    def score_step(self, context: str, step: str) -> float:\n",
    "        \"\"\"\n",
    "        Score a single reasoning step.\n",
    "\n",
    "        Returns probability that the step is correct.\n",
    "        \"\"\"\n",
    "        # Format input\n",
    "        text = f\"{context}\\n{step}\\n{self.response_template}\"\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        # Get logits for next token\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            next_token_logits = outputs.logits[0, -1, :]\n",
    "\n",
    "        # Get probabilities for + and -\n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        pos_prob = probs[self.pos_token_id].item()\n",
    "        neg_prob = probs[self.neg_token_id].item()\n",
    "\n",
    "        # Normalize to get P(correct)\n",
    "        score = pos_prob / (pos_prob + neg_prob) if (pos_prob + neg_prob) > 0 else 0.5\n",
    "\n",
    "        return score\n",
    "\n",
    "    def score_solution(self, problem: str, solution: str) -> dict:\n",
    "        \"\"\"\n",
    "        Score an entire solution by scoring each step.\n",
    "\n",
    "        Uses \"Weakest Link\" aggregation (min of step scores).\n",
    "        \"\"\"\n",
    "        # Split solution into steps\n",
    "        steps = [s.strip() for s in solution.split(\"\\n\") if s.strip()]\n",
    "\n",
    "        if not steps:\n",
    "            return {\"score\": 0.0, \"step_scores\": [], \"steps\": []}\n",
    "\n",
    "        context = f\"Problem: {problem}\\n\\nSolution:\"\n",
    "        step_scores = []\n",
    "\n",
    "        for step in steps:\n",
    "            score = self.score_step(context, step)\n",
    "            step_scores.append(score)\n",
    "            context = f\"{context}\\n{step}\"\n",
    "\n",
    "        # Aggregate using min (weakest link)\n",
    "        final_score = min(step_scores) if step_scores else 0.0\n",
    "\n",
    "        return {\n",
    "            \"score\": final_score,\n",
    "            \"step_scores\": step_scores,\n",
    "            \"steps\": steps\n",
    "        }\n",
    "\n",
    "\n",
    "# Create verifier using the trained model (already in inference mode)\n",
    "verifier = PRMVerifier(model, tokenizer)\n",
    "print(\"\\nVerifier ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "generator_class",
    "outputId": "d11839e7-e182-4f11-a595-777873d18690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized!\n",
      "\n",
      "Generator ready!\n",
      "\n",
      "Both verifier and generator are ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# Solution generator using the same trained model (already in inference mode)\n",
    "class SolutionGenerator:\n",
    "    \"\"\"\n",
    "    Generate multiple solution candidates for a math problem.\n",
    "    Uses the trained Unsloth model in inference mode.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, device: str = \"cuda\"):\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        print(\"Generator initialized!\")\n",
    "\n",
    "    def generate_solutions(\n",
    "        self,\n",
    "        problem: str,\n",
    "        n_candidates: int = 16,\n",
    "        temperature: float = 0.7,\n",
    "        max_new_tokens: int = 512\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        Generate multiple solution candidates.\n",
    "        \"\"\"\n",
    "        prompt = f\"Problem: {problem}\\n\\nSolution:\\n\"\n",
    "\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        solutions = []\n",
    "        for i in range(n_candidates):\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                    use_cache=True,\n",
    "                )\n",
    "\n",
    "            generated = self.tokenizer.decode(\n",
    "                outputs[0][inputs[\"input_ids\"].shape[1]:],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "            solutions.append(generated.strip())\n",
    "            print(f\"  Generated candidate {i+1}/{n_candidates}\")\n",
    "\n",
    "        return solutions\n",
    "\n",
    "\n",
    "# Create generator using the same trained model\n",
    "generator = SolutionGenerator(model, tokenizer)\n",
    "print(\"\\nGenerator ready!\")\n",
    "print(\"\\nBoth verifier and generator are ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "best_of_n"
   },
   "source": "# ============================================================\n# EVALUATION (Post-Restart) - Run this AFTER restarting runtime\n# ============================================================\n# DO NOT run any Unsloth cells before this!\n# Just run this cell directly after restart.\n\n# First, mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport torch\nimport torch.nn.functional as F\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport re\nimport os\n\nprint(\"=\"*60)\nprint(\"EVALUATION MODE (No Unsloth)\")\nprint(\"=\"*60)\n\n# Configuration - use Google Drive paths\nDRIVE_PROJECT_PATH = \"/content/drive/MyDrive/Colab Notebooks/PRM-Math\"\nPRM_MODEL_PATH = f\"{DRIVE_PROJECT_PATH}/checkpoints/merged_model\"\nBASE_MODEL_NAME = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"  # For generation\nVERIFY_TOKEN = \"<|verify|>\"\n\n# Check if PRM model exists\nif not os.path.exists(PRM_MODEL_PATH):\n    print(f\"ERROR: PRM model not found at {PRM_MODEL_PATH}\")\n    print(\"Please make sure training completed and model was saved.\")\n    print(\"\\nAvailable files in checkpoints:\")\n    checkpoint_dir = f\"{DRIVE_PROJECT_PATH}/checkpoints\"\n    if os.path.exists(checkpoint_dir):\n        for item in os.listdir(checkpoint_dir):\n            print(f\"  - {item}\")\nelse:\n    print(f\"PRM model found at: {PRM_MODEL_PATH}\")\n    print(f\"Base model: {BASE_MODEL_NAME}\")\n    print(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjU5JckWMr4A",
    "outputId": "14391959-defb-42b0-8b6c-91d4f91b60b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION MODE (No Unsloth)\n",
      "============================================================\n",
      "PRM model found at: ./checkpoints/merged_model\n",
      "Base model: Qwen/Qwen2.5-Math-1.5B-Instruct\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATION (Post-Restart) - Run this AFTER restarting runtime\n",
    "# ============================================================\n",
    "# DO NOT run any Unsloth cells before this!\n",
    "# Just run this cell directly after restart.\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION MODE (No Unsloth)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "PRM_MODEL_PATH = \"./checkpoints/merged_model\"  # Your trained PRM\n",
    "BASE_MODEL_NAME = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"  # For generation\n",
    "VERIFY_TOKEN = \"<|verify|>\"\n",
    "\n",
    "# Check if PRM model exists\n",
    "import os\n",
    "if not os.path.exists(PRM_MODEL_PATH):\n",
    "    print(f\"ERROR: PRM model not found at {PRM_MODEL_PATH}\")\n",
    "    print(\"Please make sure training completed and model was saved.\")\n",
    "else:\n",
    "    print(f\"PRM model found at: {PRM_MODEL_PATH}\")\n",
    "    print(f\"Base model: {BASE_MODEL_NAME}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1hCn-hkMr4A",
    "outputId": "9fad24a2-1f8d-4e43-fb15-6c895b4d031e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BASE model for generation...\n",
      "Base model loaded: Qwen/Qwen2.5-Math-1.5B-Instruct\n",
      "\n",
      "Loading PRM model for scoring...\n",
      "PRM model loaded from: ./checkpoints/merged_model\n",
      "Token IDs: ' +' = 488, ' -' = 481\n",
      "\n",
      "Both models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load BASE model for generation (clean, no Unsloth patches)\n",
    "print(\"Loading BASE model for generation...\")\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "base_model.eval()\n",
    "\n",
    "if base_tokenizer.pad_token is None:\n",
    "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "\n",
    "print(f\"Base model loaded: {BASE_MODEL_NAME}\")\n",
    "\n",
    "# Load PRM model for scoring\n",
    "print(\"\\nLoading PRM model for scoring...\")\n",
    "prm_tokenizer = AutoTokenizer.from_pretrained(PRM_MODEL_PATH)\n",
    "prm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    PRM_MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "prm_model.eval()\n",
    "\n",
    "if prm_tokenizer.pad_token is None:\n",
    "    prm_tokenizer.pad_token = prm_tokenizer.eos_token\n",
    "\n",
    "# FIXED: Use correct token IDs (with leading space)\n",
    "pos_token_id = prm_tokenizer.encode(\" +\", add_special_tokens=False)[0]  # ' +' not '+'\n",
    "neg_token_id = prm_tokenizer.encode(\" -\", add_special_tokens=False)[0]  # ' -' not '-'\n",
    "\n",
    "print(f\"PRM model loaded from: {PRM_MODEL_PATH}\")\n",
    "print(f\"Token IDs: ' +' = {pos_token_id}, ' -' = {neg_token_id}\")\n",
    "print(\"\\nBoth models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8oiHGrB0Mr4A",
    "outputId": "ac8a137a-f7a4-46c1-caa7-2f546e7d275a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for evaluation\n",
    "\n",
    "def generate_solution(problem, temperature=0.7, max_new_tokens=512):\n",
    "    \"\"\"Generate a solution using the BASE model.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math assistant. Solve the problem step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": problem}\n",
    "    ]\n",
    "    prompt = base_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = base_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Handle temperature=0 (greedy) vs temperature>0 (sampling)\n",
    "        if temperature == 0 or temperature is None:\n",
    "            outputs = base_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,  # Greedy decoding\n",
    "                pad_token_id=base_tokenizer.pad_token_id,\n",
    "            )\n",
    "        else:\n",
    "            outputs = base_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                do_sample=True,\n",
    "                pad_token_id=base_tokenizer.pad_token_id,\n",
    "            )\n",
    "\n",
    "    generated = base_tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "    return generated.strip()\n",
    "\n",
    "\n",
    "def score_solution(problem, solution):\n",
    "    \"\"\"Score a solution using the PRM model with product aggregation.\"\"\"\n",
    "    steps = [s.strip() for s in solution.split(\"\\n\") if s.strip()]\n",
    "\n",
    "    if not steps:\n",
    "        return 0.0, []\n",
    "\n",
    "    context = f\"Problem: {problem}\\n\\nSolution:\"\n",
    "    step_scores = []\n",
    "\n",
    "    for step in steps:\n",
    "        text = f\"{context}\\n{step}\\n{VERIFY_TOKEN}\"\n",
    "        inputs = prm_tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = prm_model(**inputs)\n",
    "            logits = outputs.logits[0, -1, :]\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        pos_prob = probs[pos_token_id].item()\n",
    "        neg_prob = probs[neg_token_id].item()\n",
    "\n",
    "        if pos_prob + neg_prob > 0:\n",
    "            score = pos_prob / (pos_prob + neg_prob)\n",
    "        else:\n",
    "            score = 0.5\n",
    "\n",
    "        step_scores.append(score)\n",
    "        context = f\"{context}\\n{step}\"\n",
    "\n",
    "    # Product aggregation\n",
    "    import math\n",
    "    final_score = math.prod(step_scores) if step_scores else 0.0\n",
    "    return final_score, step_scores\n",
    "\n",
    "\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract numerical answer from solution text.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Try \\boxed{} format\n",
    "    boxed_match = re.search(r\"\\\\boxed\\{([^}]+)\\}\", text)\n",
    "    if boxed_match:\n",
    "        return boxed_match.group(1).strip()\n",
    "    \n",
    "    # Try #### format (GSM8K style)\n",
    "    if \"####\" in text:\n",
    "        answer = text.split(\"####\")[-1].strip()\n",
    "        # Clean up the answer\n",
    "        answer = re.sub(r\"[^\\d\\.\\-]\", \"\", answer)\n",
    "        if answer:\n",
    "            try:\n",
    "                return str(float(answer))\n",
    "            except:\n",
    "                return answer\n",
    "    \n",
    "    # Try \"The answer is X\" format\n",
    "    answer_match = re.search(r\"[Tt]he (?:final )?answer is[:\\s]*([\\d\\.\\-,]+)\", text)\n",
    "    if answer_match:\n",
    "        answer = answer_match.group(1).replace(\",\", \"\")\n",
    "        try:\n",
    "            return str(float(answer))\n",
    "        except:\n",
    "            return answer\n",
    "    \n",
    "    # Try to find last number\n",
    "    numbers = re.findall(r\"[-]?\\d+\\.?\\d*\", text)\n",
    "    if numbers:\n",
    "        try:\n",
    "            return str(float(numbers[-1]))\n",
    "        except:\n",
    "            return numbers[-1]\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"Helper functions defined:\")\n",
    "print(\"- generate_solution(problem, temperature=0.7) - handles temp=0 correctly\")\n",
    "print(\"- score_solution(problem, solution) - PRM scoring with product aggregation\")\n",
    "print(\"- extract_answer(text) - extracts numerical answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "demo_header",
    "outputId": "32f3277b-6403-4f2b-b6fe-2f8b2528ba94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GSM8K dataset...\n",
      "\n",
      "Evaluating 50 problems with 8 candidates...\n",
      "BASE model for generation, PRM for scoring\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|\u258f         | 1/50 [01:32<1:15:55, 92.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- First Problem Debug ---\n",
      "Q: Janet\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning an...\n",
      "GT: 18.0\n",
      "Answers: ['18.0', '18.0', '18.0', '18.0', '14.0', '18.0', '18.0', '18.0']\n",
      "PRM scores: ['0.032', '0.029', '0.279', '0.060', '0.015', '0.080', '0.101', '0.137']\n",
      "Answer weights: {'18.0': 0.7175781479270358, '14.0': 0.014636016999102351}\n",
      "Weighted best: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [1:19:25<00:00, 95.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Problems: 50\n",
      "Candidates per problem: 8\n",
      "--------------------------------------------------\n",
      "Pass@1:           40/50 = 80.0%\n",
      "Majority@8:        45/50 = 90.0%\n",
      "PRM Rerank@8:      42/50 = 84.0%\n",
      "PRM-Weighted@8:    43/50 = 86.0%\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_gsm8k(n_problems=20, n_candidates=4, temperature=0.7):\n",
    "    \"\"\"Evaluate with multiple methods including PRM-weighted majority.\"\"\"\n",
    "\n",
    "    print(\"Loading GSM8K dataset...\")\n",
    "    gsm8k = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "    problems = list(gsm8k)[:n_problems]\n",
    "\n",
    "    results = {\"pass_1\": 0, \"majority\": 0, \"prm_rerank\": 0, \"prm_weighted\": 0, \"total\": 0}\n",
    "\n",
    "    print(f\"\\nEvaluating {n_problems} problems with {n_candidates} candidates...\")\n",
    "    print(\"BASE model for generation, PRM for scoring\\n\")\n",
    "\n",
    "    for idx, item in enumerate(tqdm(problems)):\n",
    "        question = item[\"question\"]\n",
    "        gt_match = re.search(r\"####\\s*([-\\d,\\.]+)\", item[\"answer\"])\n",
    "        if not gt_match:\n",
    "            continue\n",
    "        ground_truth = str(float(gt_match.group(1).replace(\",\", \"\")))\n",
    "\n",
    "        # Generate N candidates\n",
    "        solutions = [generate_solution(question, temperature) for _ in range(n_candidates)]\n",
    "\n",
    "        # Score all solutions\n",
    "        scored = [(sol, score_solution(question, sol)[0]) for sol in solutions]\n",
    "        answers = [extract_answer(sol) for sol in solutions]\n",
    "        scores = [s[1] for s in scored]\n",
    "\n",
    "        # Pass@1\n",
    "        if answers[0] == ground_truth:\n",
    "            results[\"pass_1\"] += 1\n",
    "\n",
    "        # Pure Majority vote\n",
    "        from collections import Counter\n",
    "        valid = [a for a in answers if a]\n",
    "        if valid:\n",
    "            majority = Counter(valid).most_common(1)[0][0]\n",
    "            if majority == ground_truth:\n",
    "                results[\"majority\"] += 1\n",
    "\n",
    "        # PRM Rerank (best score)\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_answer = extract_answer(scored[0][0])\n",
    "        if best_answer == ground_truth:\n",
    "            results[\"prm_rerank\"] += 1\n",
    "\n",
    "        # PRM-Weighted Majority (NEW)\n",
    "        answer_weights = {}\n",
    "        for ans, score in zip(answers, scores):\n",
    "            if ans:\n",
    "                answer_weights[ans] = answer_weights.get(ans, 0) + score\n",
    "        if answer_weights:\n",
    "            weighted_best = max(answer_weights, key=answer_weights.get)\n",
    "            if weighted_best == ground_truth:\n",
    "                results[\"prm_weighted\"] += 1\n",
    "\n",
    "        results[\"total\"] += 1\n",
    "\n",
    "        # Debug first problem\n",
    "        if idx == 0:\n",
    "            print(f\"\\n--- First Problem Debug ---\")\n",
    "            print(f\"Q: {question[:80]}...\")\n",
    "            print(f\"GT: {ground_truth}\")\n",
    "            print(f\"Answers: {answers}\")\n",
    "            print(f\"PRM scores: {[f'{s:.3f}' for s in scores]}\")\n",
    "            print(f\"Answer weights: {answer_weights}\")\n",
    "            print(f\"Weighted best: {weighted_best if answer_weights else 'N/A'}\")\n",
    "\n",
    "    # Results\n",
    "    total = results[\"total\"]\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Problems: {total}\")\n",
    "    print(f\"Candidates per problem: {n_candidates}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Pass@1:           {results['pass_1']}/{total} = {results['pass_1']/total*100:.1f}%\")\n",
    "    print(f\"Majority@{n_candidates}:        {results['majority']}/{total} = {results['majority']/total*100:.1f}%\")\n",
    "    print(f\"PRM Rerank@{n_candidates}:      {results['prm_rerank']}/{total} = {results['prm_rerank']/total*100:.1f}%\")\n",
    "    print(f\"PRM-Weighted@{n_candidates}:    {results['prm_weighted']}/{total} = {results['prm_weighted']/total*100:.1f}%\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "eval_results = evaluate_gsm8k(n_problems=50, n_candidates=8, temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 559,
     "referenced_widgets": [
      "0826a059e93d41f6bfa59e774b35fc0d",
      "b186234c00a74a2088fb7e96074d0cd1",
      "28f844656d494a71851309e6d9ede971",
      "705edc11f4304afdb2f8be883b0bbcb9",
      "778ec019c31c4b7ba078811cdc7a3224",
      "a5a3fe77bc434ce5b0c2ed2e24465359",
      "cd7f0a52c6fe432488f1c1d285ea7c1d",
      "911a3a6b9aea4ce58431a7fc7d17d4de",
      "4a6fbf9761a0497faa0fdc3f783bbe05",
      "77370177a5f74d30abdd6bfe5b838a31",
      "dadb6e2ea5394eacbe74f98901ab663e",
      "72fcbc845f9243b0b0900d087189e534",
      "11f7044cc9014182b07c59d7e02ffe9f",
      "4a12e75d19ba42028c1fa45c67a0bce8",
      "0c14d08de8e641288a439f1cf3636e80",
      "9d0ba508edff49c9b57456adc37ac6ed",
      "6fd8ce334a004be2a66af0cbf4248f55",
      "ef5db529f1c44a5d981bc7d3e8912a14",
      "621965104b6c456d9b488ed0479330f8",
      "3cf8168e73084be8b66e8b2f9d727710",
      "0dd34920d0a449d1b32de0e4da9a9bf5",
      "84508c33092044ccbaf138a80ed08b15",
      "4c1babb43387427f87de54567301ab14",
      "08965a6842a14a5d9cedd1f91f32765b",
      "8ade6c47b996408cafd13f600d3d593a",
      "d461eae934a240a0bffeb0be448f9143",
      "595fd4461df44cd1b16c0e016b786890",
      "af0c868720fe40a2900795917050954b",
      "c6c06ee2cdea4d048c0718f982f73e59",
      "1c897a49bb934d2db5d79a7f89040c22",
      "62589bee47f642d2a94a77a18e7598e3",
      "f6af3b8bf9d44b6f86494a3e4e385c04",
      "8f657afefce648ea81b0ff1900c89f73"
     ]
    },
    "id": "SwO40t_LtYGw",
    "outputId": "a429f466-2a1b-491d-c1e7-b55f495791a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATH-500 evaluation ready!\n",
      "This dataset contains competition-level problems (AMC, AIME style)\n",
      "Loading MATH-500 dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0826a059e93d41f6bfa59e774b35fc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/412 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fcbc845f9243b0b0900d087189e534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1babb43387427f87de54567301ab14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 problems\n",
      "Columns: ['problem', 'solution', 'answer', 'subject', 'level', 'unique_id']\n",
      "\n",
      "Evaluating 50 problems with 8 candidates...\n",
      "BASE model for generation, PRM for scoring\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|\u258f         | 1/50 [01:55<1:34:03, 115.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Problem 1 ---\n",
      "Q: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the...\n",
      "GT: (3,2)\n",
      "Answers: ['(3,2)', 'math.atan(y/x', '(3,2)', '(3,2)']\n",
      "Scores: ['0.020', '0.013', '0.037', '0.045']\n",
      "Best: (3,2) | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  4%|\u258d         | 2/50 [04:23<1:47:51, 134.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Problem 2 ---\n",
      "Q: Define\n",
      "\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} \\quad q = \\sum_{k = 1}^\\infty \\frac{...\n",
      "GT: p-q\n",
      "Answers: ['1^1n^2=p', '2^1n^2=p-1and_', '1^1n^2=pand', '2^(1n^2-1n^3)=(']\n",
      "Scores: ['0.079', '0.024', '0.202', '0.014']\n",
      "Best: 1^1n^2=pand | Correct: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [1:41:20<00:00, 121.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "MATH-500 EVALUATION RESULTS\n",
      "=======================================================\n",
      "Problems: 50 | Candidates: 8\n",
      "-------------------------------------------------------\n",
      "Pass@1:           24/50 = 48.0%\n",
      "Majority@8:        27/50 = 54.0%\n",
      "PRM Rerank@8:      27/50 = 54.0%\n",
      "PRM-Weighted@8:    27/50 = 54.0%\n",
      "=======================================================\n",
      "\n",
      "PRM Rerank improvement: +6.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MATH-500 Dataset Evaluation (Competition-level math problems)\n",
    "import re\n",
    "import math\n",
    "\n",
    "def normalize_math_answer(answer):\n",
    "    \"\"\"Normalize MATH dataset answers for comparison.\"\"\"\n",
    "    if answer is None:\n",
    "        return None\n",
    "\n",
    "    answer = str(answer).strip()\n",
    "\n",
    "    # Remove LaTeX formatting\n",
    "    answer = answer.replace(\"\\\\$\", \"\").replace(\"$\", \"\")\n",
    "    answer = answer.replace(\"\\\\%\", \"%\").replace(\"\\\\!\", \"\")\n",
    "\n",
    "    # Handle common LaTeX commands\n",
    "    answer = re.sub(r'\\\\text\\{([^}]*)\\}', r'\\1', answer)\n",
    "    answer = re.sub(r'\\\\textbf\\{([^}]*)\\}', r'\\1', answer)\n",
    "    answer = re.sub(r'\\\\mathrm\\{([^}]*)\\}', r'\\1', answer)\n",
    "    answer = re.sub(r'\\\\left|\\\\right', '', answer)\n",
    "\n",
    "    # Handle fractions: \\frac{a}{b}\n",
    "    frac_match = re.search(r'\\\\d?frac\\{([^}]*)\\}\\{([^}]*)\\}', answer)\n",
    "    if frac_match:\n",
    "        try:\n",
    "            num = float(frac_match.group(1))\n",
    "            den = float(frac_match.group(2))\n",
    "            if den != 0:\n",
    "                answer = str(num / den)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Handle sqrt\n",
    "    sqrt_match = re.search(r'\\\\sqrt\\{([^}]*)\\}', answer)\n",
    "    if sqrt_match:\n",
    "        try:\n",
    "            val = float(sqrt_match.group(1))\n",
    "            answer = str(math.sqrt(val))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Remove remaining LaTeX commands\n",
    "    answer = re.sub(r'\\\\[a-zA-Z]+', '', answer)\n",
    "    answer = answer.replace(\"{\", \"\").replace(\"}\", \"\").replace(\" \", \"\").strip()\n",
    "\n",
    "    try:\n",
    "        return str(float(answer))\n",
    "    except:\n",
    "        return answer.lower()\n",
    "\n",
    "\n",
    "def extract_math_answer(text):\n",
    "    \"\"\"Extract answer from MATH-style solutions.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    # Try \\boxed{answer}\n",
    "    boxed_patterns = [\n",
    "        r'\\\\boxed\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}',\n",
    "        r'\\\\boxed\\{([^}]+)\\}',\n",
    "    ]\n",
    "    for pattern in boxed_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        if matches:\n",
    "            return normalize_math_answer(matches[-1])\n",
    "\n",
    "    # Try \"the answer is X\" patterns\n",
    "    answer_patterns = [\n",
    "        r'[Tt]he\\s+(?:final\\s+)?answer\\s+is[:\\s]*\\$?([^\\$\\n]+)\\$?',\n",
    "        r'[Aa]nswer[:\\s]*\\$?([^\\$\\n]+)\\$?',\n",
    "        r'=\\s*\\$?([^\\$\\n]+)\\$?\\s*$',\n",
    "    ]\n",
    "    for pattern in answer_patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return normalize_math_answer(match.group(1))\n",
    "\n",
    "    # Fallback: last number\n",
    "    numbers = re.findall(r'([+-]?\\d+\\.?\\d*)', text)\n",
    "    if numbers:\n",
    "        return normalize_math_answer(numbers[-1])\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_math_answer(predicted, ground_truth):\n",
    "    \"\"\"Check if predicted answer matches ground truth.\"\"\"\n",
    "    if predicted is None or ground_truth is None:\n",
    "        return False\n",
    "\n",
    "    pred_norm = normalize_math_answer(predicted)\n",
    "    gt_norm = normalize_math_answer(ground_truth)\n",
    "\n",
    "    if pred_norm is None or gt_norm is None:\n",
    "        return False\n",
    "\n",
    "    if pred_norm == gt_norm:\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        return abs(float(pred_norm) - float(gt_norm)) < 1e-4\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evaluate_math500(n_problems=50, n_candidates=8, temperature=0.8):\n",
    "    \"\"\"Evaluate on MATH-500 dataset (competition-level problems).\"\"\"\n",
    "\n",
    "    print(\"Loading MATH-500 dataset...\")\n",
    "    try:\n",
    "        math_dataset = load_dataset(\"HuggingFaceH4/MATH-500\", split=\"test\")\n",
    "        print(f\"Loaded {len(math_dataset)} problems\")\n",
    "        print(f\"Columns: {math_dataset.column_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MATH-500: {e}\")\n",
    "        print(\"\\nTrying alternative: openai/gsm8k hard subset...\")\n",
    "        # Fallback to harder GSM8K problems\n",
    "        math_dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "        # Take later problems (tend to be harder)\n",
    "        math_dataset = math_dataset.select(range(len(math_dataset)-500, len(math_dataset)))\n",
    "        print(f\"Using last 500 GSM8K problems (harder subset)\")\n",
    "\n",
    "    problems = list(math_dataset)[:n_problems]\n",
    "\n",
    "    results = {\"pass_1\": 0, \"majority\": 0, \"prm_rerank\": 0, \"prm_weighted\": 0, \"total\": 0}\n",
    "\n",
    "    print(f\"\\nEvaluating {len(problems)} problems with {n_candidates} candidates...\")\n",
    "    print(\"BASE model for generation, PRM for scoring\\n\")\n",
    "\n",
    "    for idx, item in enumerate(tqdm(problems)):\n",
    "        # Handle different column names\n",
    "        problem = item.get(\"problem\", item.get(\"question\", \"\"))\n",
    "\n",
    "        # Get ground truth\n",
    "        if \"answer\" in item:\n",
    "            gt_answer = normalize_math_answer(item[\"answer\"])\n",
    "        elif \"solution\" in item:\n",
    "            gt_answer = extract_math_answer(item[\"solution\"])\n",
    "        else:\n",
    "            # GSM8K format\n",
    "            gt_match = re.search(r\"####\\s*([-\\d,\\.]+)\", item.get(\"answer\", \"\"))\n",
    "            gt_answer = str(float(gt_match.group(1).replace(\",\", \"\"))) if gt_match else None\n",
    "\n",
    "        if not problem or gt_answer is None:\n",
    "            continue\n",
    "\n",
    "        # Generate candidates\n",
    "        solutions = [generate_solution(problem, temperature) for _ in range(n_candidates)]\n",
    "        scored = [(sol, score_solution(problem, sol)[0]) for sol in solutions]\n",
    "        answers = [extract_math_answer(sol) for sol in solutions]\n",
    "        scores = [s[1] for s in scored]\n",
    "\n",
    "        # Pass@1\n",
    "        if check_math_answer(answers[0], gt_answer):\n",
    "            results[\"pass_1\"] += 1\n",
    "\n",
    "        # Majority vote\n",
    "        from collections import Counter\n",
    "        valid = [a for a in answers if a]\n",
    "        if valid:\n",
    "            majority = Counter(valid).most_common(1)[0][0]\n",
    "            if check_math_answer(majority, gt_answer):\n",
    "                results[\"majority\"] += 1\n",
    "\n",
    "        # PRM Rerank\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_answer = extract_math_answer(scored[0][0])\n",
    "        if check_math_answer(best_answer, gt_answer):\n",
    "            results[\"prm_rerank\"] += 1\n",
    "\n",
    "        # PRM-Weighted Majority\n",
    "        answer_weights = {}\n",
    "        for ans, score in zip(answers, scores):\n",
    "            if ans:\n",
    "                found = False\n",
    "                for existing in answer_weights:\n",
    "                    if check_math_answer(ans, existing):\n",
    "                        answer_weights[existing] += score\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    answer_weights[ans] = score\n",
    "\n",
    "        if answer_weights:\n",
    "            weighted_best = max(answer_weights, key=answer_weights.get)\n",
    "            if check_math_answer(weighted_best, gt_answer):\n",
    "                results[\"prm_weighted\"] += 1\n",
    "\n",
    "        results[\"total\"] += 1\n",
    "\n",
    "        # Debug first 2 problems\n",
    "        if idx < 2:\n",
    "            print(f\"\\n--- Problem {idx+1} ---\")\n",
    "            print(f\"Q: {problem[:100]}...\")\n",
    "            print(f\"GT: {gt_answer}\")\n",
    "            print(f\"Answers: {answers[:4]}\")\n",
    "            print(f\"Scores: {[f'{s:.3f}' for s in scores[:4]]}\")\n",
    "            print(f\"Best: {best_answer} | Correct: {check_math_answer(best_answer, gt_answer)}\")\n",
    "\n",
    "    # Results\n",
    "    total = results[\"total\"]\n",
    "    print(\"\\n\" + \"=\"*55)\n",
    "    print(\"MATH-500 EVALUATION RESULTS\")\n",
    "    print(\"=\"*55)\n",
    "    print(f\"Problems: {total} | Candidates: {n_candidates}\")\n",
    "    print(\"-\"*55)\n",
    "    print(f\"Pass@1:           {results['pass_1']}/{total} = {results['pass_1']/total*100:.1f}%\")\n",
    "    print(f\"Majority@{n_candidates}:        {results['majority']}/{total} = {results['majority']/total*100:.1f}%\")\n",
    "    print(f\"PRM Rerank@{n_candidates}:      {results['prm_rerank']}/{total} = {results['prm_rerank']/total*100:.1f}%\")\n",
    "    print(f\"PRM-Weighted@{n_candidates}:    {results['prm_weighted']}/{total} = {results['prm_weighted']/total*100:.1f}%\")\n",
    "    print(\"=\"*55)\n",
    "    print(f\"\\nPRM Rerank improvement: {(results['prm_rerank']-results['pass_1'])/total*100:+.1f}%\")\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"MATH-500 evaluation ready!\")\n",
    "print(\"This dataset contains competition-level problems (AMC, AIME style)\")\n",
    "\n",
    "# Run MATH-500 Evaluation\n",
    "# Competition-level problems - expect lower accuracy but more PRM benefit\n",
    "\n",
    "# Standard evaluation (~2 hours)\n",
    "math_results = evaluate_math500(n_problems=50, n_candidates=8, temperature=0.8)\n",
    "\n",
    "# Quick test (~30 min)\n",
    "# math_results = evaluate_math500(n_problems=20, n_candidates=4, temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MCTS with PRM Value Function\n",
    "\n",
    "Monte Carlo Tree Search using the trained PRM as the value function.\n",
    "- **Prior**: LLM generation probability (temperature sampling confidence)\n",
    "- **Value**: PRM score for the current solution state\n",
    "- **Selection**: UCB with exploration bonus\n",
    "- **Expansion**: Generate candidate next steps\n",
    "- **Evaluation**: PRM scores the partial solution\n",
    "- **Backpropagation**: Update visit counts and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# ============================================================\n",
    "# MCTS with PRM Value Function and Logprob Priors (Optimized)\n",
    "# ============================================================\n",
    "\n",
    "class MCTSNode:\n",
    "    \"\"\"Node in the MCTS tree.\"\"\"\n",
    "    def __init__(self, state, parent=None, action=None, prior=1.0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.value_sum = 0.0\n",
    "        self.prior = prior\n",
    "        self._cached_value = None\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.value_sum / (self.visits + 1e-8)\n",
    "    \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def is_terminal(self):\n",
    "        if self.action is None:\n",
    "            return False\n",
    "        return \"\\\\boxed\" in self.action or \"boxed{\" in self.action or \"####\" in self.action\n",
    "\n",
    "\n",
    "class MCTSSearchPRM:\n",
    "    \"\"\"MCTS using generation logprobs as prior and trained PRM as value function.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_model, base_tokenizer, prm_model, prm_tokenizer, \n",
    "                 pos_token_id, neg_token_id, config=None):\n",
    "        self.base_model = base_model\n",
    "        self.base_tokenizer = base_tokenizer\n",
    "        self.prm_model = prm_model\n",
    "        self.prm_tokenizer = prm_tokenizer\n",
    "        self.pos_token_id = pos_token_id\n",
    "        self.neg_token_id = neg_token_id\n",
    "        \n",
    "        self.config = config or {}\n",
    "        self.c_puct = self.config.get(\"c_puct\", 1.5)\n",
    "        self.n_expand = self.config.get(\"n_expand\", 3)\n",
    "        self.temperature = self.config.get(\"temperature\", 0.8)\n",
    "        self.max_depth = self.config.get(\"max_depth\", 10)\n",
    "    \n",
    "    def search_with_checkpoints(self, problem, max_simulations=50, checkpoints=[1, 5, 10, 20, 50]):\n",
    "        \"\"\"\n",
    "        Run MCTS once and record best solution at each checkpoint.\n",
    "        \n",
    "        Returns: dict mapping simulation count to best solution at that point\n",
    "        Example: {1: \"solution after 1 sim\", 5: \"solution after 5 sims\", ...}\n",
    "        \"\"\"\n",
    "        # Create root node\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful math assistant. Solve the problem step by step.\"},\n",
    "            {\"role\": \"user\", \"content\": problem}\n",
    "        ]\n",
    "        root_state = self.base_tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        root = MCTSNode(state=root_state, prior=1.0)\n",
    "        \n",
    "        # Sort checkpoints and ensure max_simulations covers all\n",
    "        checkpoints = sorted([c for c in checkpoints if c <= max_simulations])\n",
    "        if not checkpoints:\n",
    "            checkpoints = [max_simulations]\n",
    "        actual_max = max(checkpoints)\n",
    "        \n",
    "        results = {}\n",
    "        checkpoint_idx = 0\n",
    "        \n",
    "        for sim in range(1, actual_max + 1):\n",
    "            node = root\n",
    "            \n",
    "            # Selection\n",
    "            depth = 0\n",
    "            while node.is_fully_expanded() and not node.is_terminal() and depth < self.max_depth:\n",
    "                node = self._select_child(node)\n",
    "                depth += 1\n",
    "            \n",
    "            # Expansion\n",
    "            if not node.is_terminal() and depth < self.max_depth:\n",
    "                node = self._expand(node, problem)\n",
    "            \n",
    "            # Evaluation\n",
    "            value = self._evaluate_prm(node, problem)\n",
    "            \n",
    "            # Backpropagation\n",
    "            self._backpropagate(node, value)\n",
    "            \n",
    "            # Check if we hit a checkpoint\n",
    "            if checkpoint_idx < len(checkpoints) and sim == checkpoints[checkpoint_idx]:\n",
    "                results[sim] = self._get_best_solution(root, problem)\n",
    "                checkpoint_idx += 1\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def search(self, problem, simulations=10):\n",
    "        \"\"\"Single search returning best solution (backward compatible).\"\"\"\n",
    "        results = self.search_with_checkpoints(problem, max_simulations=simulations, checkpoints=[simulations])\n",
    "        return results.get(simulations, \"\")\n",
    "    \n",
    "    def _select_child(self, node):\n",
    "        sqrt_n = math.sqrt(max(1, node.visits))\n",
    "        \n",
    "        def ucb_score(child):\n",
    "            exploitation = child.value\n",
    "            exploration = self.c_puct * child.prior * sqrt_n / (1 + child.visits)\n",
    "            return exploitation + exploration\n",
    "        \n",
    "        return max(node.children, key=ucb_score)\n",
    "    \n",
    "    def _expand(self, node, problem):\n",
    "        candidates = self._generate_steps_with_logprobs(node.state, n=self.n_expand)\n",
    "        \n",
    "        if not candidates:\n",
    "            return node\n",
    "        \n",
    "        priors = np.array([c[1] for c in candidates])\n",
    "        priors = priors / (priors.sum() + 1e-8)\n",
    "        \n",
    "        for i, (step_text, _) in enumerate(candidates):\n",
    "            child_state = node.state + step_text\n",
    "            child = MCTSNode(child_state, parent=node, action=step_text, prior=priors[i])\n",
    "            node.children.append(child)\n",
    "        \n",
    "        return max(node.children, key=lambda c: c.prior)\n",
    "    \n",
    "    def _generate_steps_with_logprobs(self, state, n=3):\n",
    "        \"\"\"Generate n candidate next steps with proper logprob priors.\"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        inputs = self.base_tokenizer(state, return_tensors=\"pt\").to(\"cuda\")\n",
    "        input_length = inputs[\"input_ids\"].shape[1]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(n):\n",
    "                outputs = self.base_model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=150,\n",
    "                    temperature=self.temperature,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.base_tokenizer.pad_token_id,\n",
    "                    eos_token_id=self.base_tokenizer.eos_token_id,\n",
    "                    output_scores=True,\n",
    "                    return_dict_in_generate=True,\n",
    "                )\n",
    "                \n",
    "                generated_ids = outputs.sequences[0, input_length:]\n",
    "                scores = outputs.scores\n",
    "                \n",
    "                if len(scores) > 0 and len(generated_ids) > 0:\n",
    "                    total_logprob = 0.0\n",
    "                    num_tokens = 0\n",
    "                    \n",
    "                    for i, (score, token_id) in enumerate(zip(scores, generated_ids)):\n",
    "                        if token_id == self.base_tokenizer.eos_token_id:\n",
    "                            break\n",
    "                        if token_id == self.base_tokenizer.pad_token_id:\n",
    "                            continue\n",
    "                        \n",
    "                        probs = F.softmax(score[0] / self.temperature, dim=-1)\n",
    "                        token_prob = probs[token_id].item()\n",
    "                        \n",
    "                        if token_prob > 0:\n",
    "                            total_logprob += math.log(token_prob)\n",
    "                            num_tokens += 1\n",
    "                    \n",
    "                    if num_tokens > 0:\n",
    "                        avg_logprob = total_logprob / num_tokens\n",
    "                        prior = math.exp(avg_logprob)\n",
    "                    else:\n",
    "                        prior = 0.5\n",
    "                else:\n",
    "                    prior = 0.5\n",
    "                \n",
    "                generated_text = self.base_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "                step = generated_text.strip()\n",
    "                \n",
    "                if step:\n",
    "                    candidates.append((step, prior))\n",
    "        \n",
    "        if not candidates:\n",
    "            candidates = [(\"Let me solve this step by step.\", 0.5)]\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def _evaluate_prm(self, node, problem):\n",
    "        if node._cached_value is not None:\n",
    "            return node._cached_value\n",
    "        \n",
    "        solution = node.state\n",
    "        if \"<|im_start|>assistant\" in solution:\n",
    "            solution = solution.split(\"<|im_start|>assistant\")[-1]\n",
    "        \n",
    "        score = self._prm_score(problem, solution.strip())\n",
    "        node._cached_value = score\n",
    "        return score\n",
    "    \n",
    "    def _prm_score(self, problem, solution):\n",
    "        if not solution:\n",
    "            return 0.0\n",
    "        \n",
    "        steps = [s.strip() for s in solution.split(\"\\n\") if s.strip()]\n",
    "        if not steps:\n",
    "            return 0.0\n",
    "        \n",
    "        context = f\"Problem: {problem}\\n\\nSolution:\"\n",
    "        step_scores = []\n",
    "        \n",
    "        for step in steps:\n",
    "            text = f\"{context}\\n{step}\\n<|verify|>\"\n",
    "            inputs = self.prm_tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.prm_model(**inputs)\n",
    "                logits = outputs.logits[0, -1, :]\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            pos_prob = probs[self.pos_token_id].item()\n",
    "            neg_prob = probs[self.neg_token_id].item()\n",
    "            \n",
    "            if pos_prob + neg_prob > 0:\n",
    "                score = pos_prob / (pos_prob + neg_prob)\n",
    "            else:\n",
    "                score = 0.5\n",
    "            \n",
    "            step_scores.append(score)\n",
    "            context = f\"{context}\\n{step}\"\n",
    "        \n",
    "        if step_scores:\n",
    "            return math.prod(step_scores)\n",
    "        return 0.0\n",
    "    \n",
    "    def _backpropagate(self, node, value):\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.value_sum += value\n",
    "            node = node.parent\n",
    "    \n",
    "    def _get_best_solution(self, root, problem):\n",
    "        node = root\n",
    "        solution_text = \"\"\n",
    "        \n",
    "        while node.children:\n",
    "            node = max(node.children, key=lambda c: c.visits)\n",
    "            if node.action:\n",
    "                solution_text += node.action\n",
    "            \n",
    "            if node.is_terminal():\n",
    "                break\n",
    "        \n",
    "        if not node.is_terminal() and solution_text:\n",
    "            completion = self._greedy_complete(node.state)\n",
    "            solution_text += completion\n",
    "        \n",
    "        return solution_text\n",
    "    \n",
    "    def _greedy_complete(self, state):\n",
    "        inputs = self.base_tokenizer(state, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.base_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=256,\n",
    "                temperature=0.0,\n",
    "                do_sample=False,\n",
    "                pad_token_id=self.base_tokenizer.pad_token_id,\n",
    "            )\n",
    "        \n",
    "        generated = self.base_tokenizer.decode(\n",
    "            outputs[0][inputs[\"input_ids\"].shape[1]:], \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        return generated\n",
    "\n",
    "\n",
    "print(\"MCTS with checkpoints defined!\")\n",
    "print(\"- search_with_checkpoints(): Build tree ONCE, get results at multiple points\")\n",
    "print(\"- ~5x faster than running separate searches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mcts_gsm8k(n_problems=50, n_candidates=16, simulations_list=[1, 5, 10, 20, 50], temperature=0.8):\n",
    "    \"\"\"\n",
    "    Optimized evaluation with live progress indicators.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"MCTS vs Other Methods - GSM8K (Optimized)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    max_sims = max(simulations_list)\n",
    "    print(f\"\\nOptimization: MCTS tree built once to {max_sims} sims\")\n",
    "    print(f\"Checkpoints: {simulations_list}\")\n",
    "    \n",
    "    # Initialize MCTS\n",
    "    mcts_config = {\"c_puct\": 1.5, \"n_expand\": 3, \"temperature\": temperature, \"max_depth\": 10}\n",
    "    mcts = MCTSSearchPRM(\n",
    "        base_model, base_tokenizer, prm_model, prm_tokenizer,\n",
    "        pos_token_id, neg_token_id, config=mcts_config\n",
    "    )\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"\\nLoading GSM8K dataset...\")\n",
    "    gsm8k = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "    problems = list(gsm8k)[:n_problems]\n",
    "    \n",
    "    # Results storage\n",
    "    all_results = {\n",
    "        \"pass_1\": {\"correct\": 0, \"total\": 0},\n",
    "        f\"majority_{n_candidates}\": {\"correct\": 0, \"total\": 0},\n",
    "        f\"prm_rerank_{n_candidates}\": {\"correct\": 0, \"total\": 0},\n",
    "        f\"prm_weighted_{n_candidates}\": {\"correct\": 0, \"total\": 0},\n",
    "    }\n",
    "    for sims in simulations_list:\n",
    "        all_results[f\"mcts_{sims}\"] = {\"correct\": 0, \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nEvaluating {n_problems} problems with {n_candidates} candidates...\")\n",
    "    print()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Progress bar with live stats\n",
    "    pbar = tqdm(problems, desc=\"Evaluating\")\n",
    "    \n",
    "    for idx, item in enumerate(pbar):\n",
    "        question = item[\"question\"]\n",
    "        gt_match = re.search(r\"####\\s*([-\\d,\\.]+)\", item[\"answer\"])\n",
    "        if not gt_match:\n",
    "            continue\n",
    "        ground_truth = str(float(gt_match.group(1).replace(\",\", \"\")))\n",
    "        \n",
    "        # === Pass@1 ===\n",
    "        sol_1 = generate_solution(question, temperature=0.0)\n",
    "        ans_1 = extract_answer(sol_1)\n",
    "        if ans_1 == ground_truth:\n",
    "            all_results[\"pass_1\"][\"correct\"] += 1\n",
    "        all_results[\"pass_1\"][\"total\"] += 1\n",
    "        \n",
    "        # === Generate candidates ONCE ===\n",
    "        solutions = [generate_solution(question, temperature=0.7) for _ in range(n_candidates)]\n",
    "        answers = [extract_answer(s) for s in solutions]\n",
    "        scores = [score_solution(question, s)[0] for s in solutions]\n",
    "        \n",
    "        # Majority\n",
    "        valid_answers = [a for a in answers if a]\n",
    "        if valid_answers:\n",
    "            majority_ans = Counter(valid_answers).most_common(1)[0][0]\n",
    "            if majority_ans == ground_truth:\n",
    "                all_results[f\"majority_{n_candidates}\"][\"correct\"] += 1\n",
    "        all_results[f\"majority_{n_candidates}\"][\"total\"] += 1\n",
    "        \n",
    "        # PRM Rerank\n",
    "        best_idx = np.argmax(scores)\n",
    "        if answers[best_idx] == ground_truth:\n",
    "            all_results[f\"prm_rerank_{n_candidates}\"][\"correct\"] += 1\n",
    "        all_results[f\"prm_rerank_{n_candidates}\"][\"total\"] += 1\n",
    "        \n",
    "        # PRM-Weighted\n",
    "        answer_weights = {}\n",
    "        for ans, score in zip(answers, scores):\n",
    "            if ans:\n",
    "                answer_weights[ans] = answer_weights.get(ans, 0) + score\n",
    "        if answer_weights:\n",
    "            weighted_best = max(answer_weights, key=answer_weights.get)\n",
    "            if weighted_best == ground_truth:\n",
    "                all_results[f\"prm_weighted_{n_candidates}\"][\"correct\"] += 1\n",
    "        all_results[f\"prm_weighted_{n_candidates}\"][\"total\"] += 1\n",
    "        \n",
    "        # === MCTS with checkpoints ===\n",
    "        mcts_solutions = mcts.search_with_checkpoints(question, max_sims, simulations_list)\n",
    "        \n",
    "        for sims in simulations_list:\n",
    "            mcts_answer = extract_answer(mcts_solutions.get(sims, \"\"))\n",
    "            if mcts_answer == ground_truth:\n",
    "                all_results[f\"mcts_{sims}\"][\"correct\"] += 1\n",
    "            all_results[f\"mcts_{sims}\"][\"total\"] += 1\n",
    "        \n",
    "        # Update progress bar with live accuracies\n",
    "        if all_results[\"pass_1\"][\"total\"] > 0:\n",
    "            p1 = all_results[\"pass_1\"][\"correct\"] / all_results[\"pass_1\"][\"total\"] * 100\n",
    "            maj = all_results[f\"majority_{n_candidates}\"][\"correct\"] / all_results[f\"majority_{n_candidates}\"][\"total\"] * 100\n",
    "            prm = all_results[f\"prm_rerank_{n_candidates}\"][\"correct\"] / all_results[f\"prm_rerank_{n_candidates}\"][\"total\"] * 100\n",
    "            best_mcts_sims = max(simulations_list)\n",
    "            mcts_acc = all_results[f\"mcts_{best_mcts_sims}\"][\"correct\"] / max(all_results[f\"mcts_{best_mcts_sims}\"][\"total\"], 1) * 100\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                \"P@1\": f\"{p1:.0f}%\",\n",
    "                \"Maj\": f\"{maj:.0f}%\",\n",
    "                \"PRM\": f\"{prm:.0f}%\",\n",
    "                f\"MCTS@{best_mcts_sims}\": f\"{mcts_acc:.0f}%\"\n",
    "            })\n",
    "    \n",
    "    pbar.close()\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"FINAL RESULTS - GSM8K ({elapsed/60:.1f} minutes)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Method':<25} {'Correct':>8} {'Accuracy':>10}\")\n",
    "    print(\"-\"*45)\n",
    "    \n",
    "    for method, data in all_results.items():\n",
    "        if data[\"total\"] > 0:\n",
    "            acc = data[\"correct\"] / data[\"total\"] * 100\n",
    "            print(f\"{method:<25} {data['correct']:>3}/{data['total']:<3}    {acc:>6.1f}%\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"-\"*45)\n",
    "    maj_acc = all_results[f\"majority_{n_candidates}\"][\"correct\"] / max(all_results[f\"majority_{n_candidates}\"][\"total\"], 1) * 100\n",
    "    prm_acc = all_results[f\"prm_rerank_{n_candidates}\"][\"correct\"] / max(all_results[f\"prm_rerank_{n_candidates}\"][\"total\"], 1) * 100\n",
    "    \n",
    "    mcts_items = [(k, v) for k, v in all_results.items() if k.startswith(\"mcts_\")]\n",
    "    if mcts_items:\n",
    "        best_mcts = max(mcts_items, key=lambda x: x[1][\"correct\"] / max(x[1][\"total\"], 1))\n",
    "        best_mcts_acc = best_mcts[1][\"correct\"] / max(best_mcts[1][\"total\"], 1) * 100\n",
    "        print(f\"Best MCTS: {best_mcts[0]} ({best_mcts_acc:.1f}%)\")\n",
    "        print(f\"  vs Majority@{n_candidates}:    {best_mcts_acc - maj_acc:+.1f}%\")\n",
    "        print(f\"  vs PRM Rerank@{n_candidates}:  {best_mcts_acc - prm_acc:+.1f}%\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "print(\"GSM8K evaluation with live progress indicators defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mcts_math500(n_problems=50, n_candidates=16, simulations_list=[1, 5, 10, 20, 50], temperature=0.8):\n",
    "    \"\"\"\n",
    "    Optimized MATH-500 evaluation with live progress indicators.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"MCTS vs Other Methods - MATH-500 (Optimized)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    max_sims = max(simulations_list)\n",
    "    print(f\"\\nOptimization: MCTS tree built once to {max_sims} sims\")\n",
    "    \n",
    "    # Initialize MCTS\n",
    "    mcts_config = {\"c_puct\": 1.5, \"n_expand\": 3, \"temperature\": temperature, \"max_depth\": 10}\n",
    "    mcts = MCTSSearchPRM(\n",
    "        base_model, base_tokenizer, prm_model, prm_tokenizer,\n",
    "        pos_token_id, neg_token_id, config=mcts_config\n",
    "    )\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"\\nLoading MATH-500 dataset...\")\n",
    "    try:\n",
    "        math500 = load_dataset(\"HuggingFaceH4/MATH-500\", split=\"test\")\n",
    "        problems = list(math500)[:n_problems]\n",
    "        print(f\"Loaded {len(problems)} problems from MATH-500\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\\nUsing GSM8K hard subset...\")\n",
    "        gsm8k = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "        problems = list(gsm8k)[-n_problems:]\n",
    "    \n",
    "    # Results\n",
    "    all_results = {\n",
    "        \"pass_1\": {\"correct\": 0, \"total\": 0},\n",
    "        f\"majority_{n_candidates}\": {\"correct\": 0, \"total\": 0},\n",
    "        f\"prm_rerank_{n_candidates}\": {\"correct\": 0, \"total\": 0},\n",
    "        f\"prm_weighted_{n_candidates}\": {\"correct\": 0, \"total\": 0},\n",
    "    }\n",
    "    for sims in simulations_list:\n",
    "        all_results[f\"mcts_{sims}\"] = {\"correct\": 0, \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nEvaluating {len(problems)} problems...\")\n",
    "    print()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(problems, desc=\"Evaluating\")\n",
    "    \n",
    "    for idx, item in enumerate(pbar):\n",
    "        if \"problem\" in item:\n",
    "            question = item[\"problem\"]\n",
    "            ground_truth = item.get(\"answer\", \"\")\n",
    "        else:\n",
    "            question = item[\"question\"]\n",
    "            gt_match = re.search(r\"####\\s*([-\\d,\\.]+)\", item[\"answer\"])\n",
    "            ground_truth = gt_match.group(1).replace(\",\", \"\") if gt_match else \"\"\n",
    "        \n",
    "        if not ground_truth:\n",
    "            continue\n",
    "        \n",
    "        gt_normalized = normalize_math_answer(ground_truth)\n",
    "        \n",
    "        # Pass@1\n",
    "        sol_1 = generate_solution(question, temperature=0.0)\n",
    "        ans_1 = extract_answer(sol_1)\n",
    "        if compare_math_answers(ans_1, gt_normalized):\n",
    "            all_results[\"pass_1\"][\"correct\"] += 1\n",
    "        all_results[\"pass_1\"][\"total\"] += 1\n",
    "        \n",
    "        # Generate candidates\n",
    "        solutions = [generate_solution(question, temperature=0.7) for _ in range(n_candidates)]\n",
    "        answers = [extract_answer(s) for s in solutions]\n",
    "        scores = [score_solution(question, s)[0] for s in solutions]\n",
    "        \n",
    "        # Majority\n",
    "        valid_answers = [a for a in answers if a]\n",
    "        if valid_answers:\n",
    "            majority_ans = Counter(valid_answers).most_common(1)[0][0]\n",
    "            if compare_math_answers(majority_ans, gt_normalized):\n",
    "                all_results[f\"majority_{n_candidates}\"][\"correct\"] += 1\n",
    "        all_results[f\"majority_{n_candidates}\"][\"total\"] += 1\n",
    "        \n",
    "        # PRM Rerank\n",
    "        best_idx = np.argmax(scores)\n",
    "        if compare_math_answers(answers[best_idx], gt_normalized):\n",
    "            all_results[f\"prm_rerank_{n_candidates}\"][\"correct\"] += 1\n",
    "        all_results[f\"prm_rerank_{n_candidates}\"][\"total\"] += 1\n",
    "        \n",
    "        # PRM-Weighted\n",
    "        answer_weights = {}\n",
    "        for ans, score in zip(answers, scores):\n",
    "            if ans:\n",
    "                answer_weights[ans] = answer_weights.get(ans, 0) + score\n",
    "        if answer_weights:\n",
    "            weighted_best = max(answer_weights, key=answer_weights.get)\n",
    "            if compare_math_answers(weighted_best, gt_normalized):\n",
    "                all_results[f\"prm_weighted_{n_candidates}\"][\"correct\"] += 1\n",
    "        all_results[f\"prm_weighted_{n_candidates}\"][\"total\"] += 1\n",
    "        \n",
    "        # MCTS\n",
    "        mcts_solutions = mcts.search_with_checkpoints(question, max_sims, simulations_list)\n",
    "        for sims in simulations_list:\n",
    "            mcts_answer = extract_answer(mcts_solutions.get(sims, \"\"))\n",
    "            if compare_math_answers(mcts_answer, gt_normalized):\n",
    "                all_results[f\"mcts_{sims}\"][\"correct\"] += 1\n",
    "            all_results[f\"mcts_{sims}\"][\"total\"] += 1\n",
    "        \n",
    "        # Update progress\n",
    "        if all_results[\"pass_1\"][\"total\"] > 0:\n",
    "            p1 = all_results[\"pass_1\"][\"correct\"] / all_results[\"pass_1\"][\"total\"] * 100\n",
    "            maj = all_results[f\"majority_{n_candidates}\"][\"correct\"] / all_results[f\"majority_{n_candidates}\"][\"total\"] * 100\n",
    "            prm = all_results[f\"prm_rerank_{n_candidates}\"][\"correct\"] / all_results[f\"prm_rerank_{n_candidates}\"][\"total\"] * 100\n",
    "            best_mcts_sims = max(simulations_list)\n",
    "            mcts_acc = all_results[f\"mcts_{best_mcts_sims}\"][\"correct\"] / max(all_results[f\"mcts_{best_mcts_sims}\"][\"total\"], 1) * 100\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                \"P@1\": f\"{p1:.0f}%\",\n",
    "                \"Maj\": f\"{maj:.0f}%\",\n",
    "                \"PRM\": f\"{prm:.0f}%\",\n",
    "                f\"MCTS@{best_mcts_sims}\": f\"{mcts_acc:.0f}%\"\n",
    "            })\n",
    "    \n",
    "    pbar.close()\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Final results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"FINAL RESULTS - MATH-500 ({elapsed/60:.1f} minutes)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Method':<25} {'Correct':>8} {'Accuracy':>10}\")\n",
    "    print(\"-\"*45)\n",
    "    \n",
    "    for method, data in all_results.items():\n",
    "        if data[\"total\"] > 0:\n",
    "            acc = data[\"correct\"] / data[\"total\"] * 100\n",
    "            print(f\"{method:<25} {data['correct']:>3}/{data['total']:<3}    {acc:>6.1f}%\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"-\"*45)\n",
    "    maj_acc = all_results[f\"majority_{n_candidates}\"][\"correct\"] / max(all_results[f\"majority_{n_candidates}\"][\"total\"], 1) * 100\n",
    "    prm_acc = all_results[f\"prm_rerank_{n_candidates}\"][\"correct\"] / max(all_results[f\"prm_rerank_{n_candidates}\"][\"total\"], 1) * 100\n",
    "    \n",
    "    mcts_items = [(k, v) for k, v in all_results.items() if k.startswith(\"mcts_\")]\n",
    "    if mcts_items:\n",
    "        best_mcts = max(mcts_items, key=lambda x: x[1][\"correct\"] / max(x[1][\"total\"], 1))\n",
    "        best_mcts_acc = best_mcts[1][\"correct\"] / max(best_mcts[1][\"total\"], 1) * 100\n",
    "        print(f\"Best MCTS: {best_mcts[0]} ({best_mcts_acc:.1f}%)\")\n",
    "        print(f\"  vs Majority@{n_candidates}:    {best_mcts_acc - maj_acc:+.1f}%\")\n",
    "        print(f\"  vs PRM Rerank@{n_candidates}:  {best_mcts_acc - prm_acc:+.1f}%\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def normalize_math_answer(answer):\n",
    "    if answer is None:\n",
    "        return None\n",
    "    s = str(answer).strip()\n",
    "    s = re.sub(r\"\\\\(frac|dfrac)\\{([^}]+)\\}\\{([^}]+)\\}\", lambda m: f\"({m.group(2)})/({m.group(3)})\", s)\n",
    "    s = re.sub(r\"\\\\sqrt\\{([^}]+)\\}\", lambda m: f\"sqrt({m.group(1)})\", s)\n",
    "    s = re.sub(r\"\\\\[a-zA-Z]+\", \"\", s)\n",
    "    s = s.replace(\"{\", \"\").replace(\"}\", \"\").replace(\"$\", \"\").replace(\",\", \"\").strip()\n",
    "    try:\n",
    "        import math as math_module\n",
    "        return float(eval(s.replace(\"sqrt\", \"math_module.sqrt\")))\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def compare_math_answers(pred, truth):\n",
    "    if pred is None or truth is None:\n",
    "        return False\n",
    "    pred_n = normalize_math_answer(pred)\n",
    "    truth_n = normalize_math_answer(truth) if not isinstance(truth, (int, float)) else truth\n",
    "    try:\n",
    "        return abs(float(pred_n) - float(truth_n)) < 1e-4\n",
    "    except:\n",
    "        pass\n",
    "    return str(pred_n).strip().lower() == str(truth_n).strip().lower()\n",
    "\n",
    "\n",
    "print(\"MATH-500 evaluation with live progress indicators defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_comparison(n_problems=50, n_candidates=16, simulations_list=[1, 5, 10, 20, 50]):\n",
    "    \"\"\"Run optimized comparison on both datasets.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"FULL COMPARISON (Optimized)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Problems: {n_problems}, Candidates: {n_candidates}\")\n",
    "    print(f\"MCTS checkpoints: {simulations_list}\")\n",
    "    print()\n",
    "    \n",
    "    # Run evaluations\n",
    "    print(\">>> GSM8K Evaluation\")\n",
    "    gsm8k_results = evaluate_mcts_gsm8k(n_problems, n_candidates, simulations_list)\n",
    "    \n",
    "    print(\"\\n>>> MATH-500 Evaluation\")\n",
    "    math500_results = evaluate_mcts_math500(n_problems, n_candidates, simulations_list)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Bar charts\n",
    "    for ax, (title, results) in zip(axes[:2], [(\"GSM8K\", gsm8k_results), (\"MATH-500\", math500_results)]):\n",
    "        methods = []\n",
    "        accuracies = []\n",
    "        colors = []\n",
    "        \n",
    "        color_map = {\n",
    "            \"pass_1\": \"#bdc3c7\",\n",
    "            f\"majority_{n_candidates}\": \"#3498db\", \n",
    "            f\"prm_rerank_{n_candidates}\": \"#e74c3c\",\n",
    "            f\"prm_weighted_{n_candidates}\": \"#9b59b6\",\n",
    "        }\n",
    "        for sims in simulations_list:\n",
    "            color_map[f\"mcts_{sims}\"] = plt.cm.Greens(0.3 + 0.7 * simulations_list.index(sims) / len(simulations_list))\n",
    "        \n",
    "        for method, data in results.items():\n",
    "            if data[\"total\"] > 0:\n",
    "                label = method.replace(\"_\", \"@\").replace(f\"@{n_candidates}\", f\"@{n_candidates}\")\n",
    "                methods.append(label)\n",
    "                accuracies.append(data[\"correct\"] / data[\"total\"] * 100)\n",
    "                colors.append(color_map.get(method, \"#95a5a6\"))\n",
    "        \n",
    "        bars = ax.bar(methods, accuracies, color=colors, edgecolor=\"black\", linewidth=1)\n",
    "        ax.set_ylabel(\"Accuracy (%)\", fontsize=11)\n",
    "        ax.set_title(f\"{title}\", fontsize=13, fontweight=\"bold\")\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.tick_params(axis=\"x\", rotation=55, labelsize=8)\n",
    "        \n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                   f\"{acc:.0f}%\", ha=\"center\", fontsize=8)\n",
    "    \n",
    "    # MCTS Scaling plot\n",
    "    ax3 = axes[2]\n",
    "    for dataset_name, results, color, marker in [\n",
    "        (\"GSM8K\", gsm8k_results, \"#3498db\", \"o\"),\n",
    "        (\"MATH-500\", math500_results, \"#e74c3c\", \"s\")\n",
    "    ]:\n",
    "        mcts_data = [(int(k.split(\"_\")[1]), v[\"correct\"]/max(v[\"total\"],1)*100) \n",
    "                     for k, v in results.items() if k.startswith(\"mcts_\")]\n",
    "        if mcts_data:\n",
    "            mcts_data.sort()\n",
    "            sims, accs = zip(*mcts_data)\n",
    "            ax3.plot(sims, accs, marker=marker, label=f\"MCTS ({dataset_name})\", \n",
    "                    color=color, linewidth=2, markersize=8)\n",
    "            \n",
    "            maj_acc = results[f\"majority_{n_candidates}\"][\"correct\"] / max(results[f\"majority_{n_candidates}\"][\"total\"], 1) * 100\n",
    "            ax3.axhline(y=maj_acc, color=color, linestyle=\"--\", alpha=0.5)\n",
    "    \n",
    "    ax3.set_xlabel(\"MCTS Simulations\", fontsize=11)\n",
    "    ax3.set_ylabel(\"Accuracy (%)\", fontsize=11)\n",
    "    ax3.set_title(\"MCTS Scaling\", fontsize=13, fontweight=\"bold\")\n",
    "    ax3.legend(fontsize=9)\n",
    "    ax3.set_xscale(\"log\")\n",
    "    ax3.set_xticks(simulations_list)\n",
    "    ax3.set_xticklabels(simulations_list)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mcts_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    return gsm8k_results, math500_results\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"USAGE EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "print(\"# Quick test (~30-60 min)\")\n",
    "print(\"results = evaluate_mcts_gsm8k(n_problems=30, n_candidates=8, simulations_list=[1, 5, 10])\")\n",
    "print()\n",
    "print(\"# Standard evaluation (~2-3 hours)\")\n",
    "print(\"gsm8k, math500 = run_full_comparison(n_problems=50, n_candidates=16, simulations_list=[1, 5, 10, 20, 50])\")\n",
    "print()\n",
    "print(\"# Thorough evaluation (~4-6 hours)\")\n",
    "print(\"gsm8k, math500 = run_full_comparison(n_problems=100, n_candidates=16, simulations_list=[1, 5, 10, 20, 50])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0s5wOkOfmeW2",
    "outputId": "2e5128a6-e4b4-44ba-9d7b-9b824f45327f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ...2+2?\n",
      "\n",
      "Solution:\n",
      "Step 1: 2+2=4\n",
      "<|verify|>\n",
      "  P(+)=0.0000, P(-)=0.0000\n",
      "  Score: nan\n",
      "\n",
      "Text: ...2+2?\n",
      "\n",
      "Solution:\n",
      "Step 1: 2+2=5\n",
      "<|verify|>\n",
      "  P(+)=0.0000, P(-)=0.0000\n",
      "  Score: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "# Debug: Check what the trained model predicts\n",
    "test_texts = [\n",
    "    \"Problem: What is 2+2?\\n\\nSolution:\\nStep 1: 2+2=4\\n<|verify|>\",  # Correct\n",
    "    \"Problem: What is 2+2?\\n\\nSolution:\\nStep 1: 2+2=5\\n<|verify|>\",  # Wrong\n",
    "]\n",
    "\n",
    "FastLanguageModel.for_inference(prm_model)\n",
    "\n",
    "for text in test_texts:\n",
    "    inputs = prm_tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = prm_model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    pos_id = prm_tokenizer.encode(\"+\", add_special_tokens=False)[0]\n",
    "    neg_id = prm_tokenizer.encode(\"-\", add_special_tokens=False)[0]\n",
    "\n",
    "    print(f\"Text: ...{text[-40:]}\")\n",
    "    print(f\"  P(+)={probs[pos_id]:.4f}, P(-)={probs[neg_id]:.4f}\")\n",
    "    print(f\"  Score: {probs[pos_id]/(probs[pos_id]+probs[neg_id]):.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTqpLnnmoA9M",
    "outputId": "4d355630-484c-418e-a2e4-e225303b3930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 predicted tokens after <|verify|>:\n",
      "  ' +' (id=488): 0.9971\n",
      "  ' -' (id=481): 0.0031\n",
      "  '_plus' (id=28043): 0.0000\n",
      "  ' The' (id=576): 0.0000\n",
      "  ' This' (id=1096): 0.0000\n",
      "  ' x' (id=856): 0.0000\n",
      "  ' *' (id=353): 0.0000\n",
      "  ' by' (id=553): 0.0000\n",
      "  ' //' (id=442): 0.0000\n",
      "  ' (' (id=320): 0.0000\n",
      "\n",
      "Our assumed token IDs:\n",
      "  '+' token ID: 10, prob: 0.000000\n",
      "  '-' token ID: 12, prob: 0.000000\n",
      "\n",
      "Alternative '+' encodings:\n",
      "  '+' -> [10]\n",
      "  ' +' -> [488]\n",
      "  '+ ' -> [10, 220]\n",
      "  ' + ' -> [488, 220]\n"
     ]
    }
   ],
   "source": [
    "# Debug: What tokens is the model actually predicting?\n",
    "test_text = \"Problem: What is 2+2?\\n\\nSolution:\\nStep 1: 2+2=4\\n<|verify|>\"\n",
    "\n",
    "inputs = prm_tokenizer(test_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    outputs = prm_model(**inputs)\n",
    "    logits = outputs.logits[0, -1, :]\n",
    "\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "# Top 10 predicted tokens\n",
    "top_probs, top_ids = torch.topk(probs, 10)\n",
    "print(\"Top 10 predicted tokens after <|verify|>:\")\n",
    "for prob, tok_id in zip(top_probs, top_ids):\n",
    "    token = prm_tokenizer.decode([tok_id])\n",
    "    print(f\"  '{token}' (id={tok_id.item()}): {prob.item():.4f}\")\n",
    "\n",
    "# Check our assumed token IDs\n",
    "print(f\"\\nOur assumed token IDs:\")\n",
    "pos_id = prm_tokenizer.encode(\"+\", add_special_tokens=False)[0]\n",
    "neg_id = prm_tokenizer.encode(\"-\", add_special_tokens=False)[0]\n",
    "print(f\"  '+' token ID: {pos_id}, prob: {probs[pos_id].item():.6f}\")\n",
    "print(f\"  '-' token ID: {neg_id}, prob: {probs[neg_id].item():.6f}\")\n",
    "\n",
    "# Also check alternative encodings\n",
    "print(f\"\\nAlternative '+' encodings:\")\n",
    "for text in [\"+\", \" +\", \"+ \", \" + \"]:\n",
    "    ids = prm_tokenizer.encode(text, add_special_tokens=False)\n",
    "    print(f\"  '{text}' -> {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_demo"
   },
   "outputs": [],
   "source": [
    "# Interactive Demo (Post-Restart)\n",
    "# Run this AFTER cells 20-22 to test specific problems\n",
    "\n",
    "#@title Enter your math problem\n",
    "problem = \"If a train travels at 60 mph for 2.5 hours, how far does it travel?\" #@param {type:\"string\"}\n",
    "n_candidates = 4 #@param {type:\"slider\", min:2, max:8, step:1}\n",
    "\n",
    "print(f\"Problem: {problem}\\n\")\n",
    "print(f\"Generating {n_candidates} solutions with BASE model...\")\n",
    "\n",
    "solutions = []\n",
    "for i in range(n_candidates):\n",
    "    sol = generate_solution(problem, temperature=0.7)\n",
    "    solutions.append(sol)\n",
    "    print(f\"  Generated candidate {i+1}/{n_candidates}\")\n",
    "\n",
    "print(\"\\nScoring with PRM model...\")\n",
    "scored = []\n",
    "for i, sol in enumerate(solutions):\n",
    "    score, step_scores = score_solution(problem, sol)\n",
    "    scored.append((sol, score, step_scores))\n",
    "    print(f\"  Scored candidate {i+1}/{n_candidates}: {score:.3f}\")\n",
    "\n",
    "# Sort by score\n",
    "scored.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST SOLUTION (Rank #1)\")\n",
    "print(\"=\"*60)\n",
    "best_sol, best_score, best_step_scores = scored[0]\n",
    "print(f\"PRM Score: {best_score:.4f}\")\n",
    "print(f\"Extracted Answer: {extract_answer(best_sol)}\")\n",
    "print(\"\\nSolution:\")\n",
    "print(\"-\"*40)\n",
    "print(best_sol)\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"\\nStep scores:\")\n",
    "steps = [s.strip() for s in best_sol.split(\"\\n\") if s.strip()]\n",
    "for i, (step, score) in enumerate(zip(steps, best_step_scores)):\n",
    "    status = \"\u2713\" if score > 0.5 else \"\u2717\"\n",
    "    preview = step[:60] + \"...\" if len(step) > 60 else step\n",
    "    print(f\"  {status} Step {i+1} ({score:.3f}): {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eval_header"
   },
   "source": [
    "---\n",
    "\n",
    "## Alternative: Quick Test WITHOUT Restarting (Lower Quality)\n",
    "\n",
    "The cells below use the fine-tuned model for BOTH generation and scoring. This works without restart but produces lower quality results because the PRM was trained for verification, not generation.\n",
    "\n",
    "**Recommended**: Use the \"Evaluation (Post-Restart)\" section above for proper results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval_setup"
   },
   "outputs": [],
   "source": [
    "# Quick test function (works without restart, but lower quality)\n",
    "# Uses the fine-tuned model for both generation and scoring\n",
    "\n",
    "def best_of_n_search_quick(problem, n_candidates=4, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Quick Best-of-N search using the trained model for both generation and scoring.\n",
    "    Note: This is suboptimal - for best results, restart runtime and use base model.\n",
    "    \"\"\"\n",
    "    print(f\"Generating {n_candidates} solutions...\")\n",
    "    solutions = generator.generate_solutions(problem, n_candidates=n_candidates, temperature=temperature)\n",
    "\n",
    "    print(\"Scoring solutions with PRM...\")\n",
    "    scored = []\n",
    "    for i, sol in enumerate(solutions):\n",
    "        result = verifier.score_solution(problem, sol)\n",
    "        scored.append({\n",
    "            \"solution\": sol,\n",
    "            \"score\": result[\"score\"],\n",
    "            \"step_scores\": result[\"step_scores\"],\n",
    "            \"steps\": result[\"steps\"]\n",
    "        })\n",
    "\n",
    "    scored.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return {\n",
    "        \"best_solution\": scored[0],\n",
    "        \"all_solutions\": scored\n",
    "    }\n",
    "\n",
    "def extract_answer_simple(text):\n",
    "    \"\"\"Extract numerical answer from solution.\"\"\"\n",
    "    import re\n",
    "    patterns = [\n",
    "        r\"[Tt]he answer is[:\\s]*([-\\d,\\.]+)\",\n",
    "        r\"=\\s*([-\\d,\\.]+)\\s*$\",\n",
    "        r\"([-\\d,\\.]+)\\s*$\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            try:\n",
    "                return str(float(match.group(1).replace(\",\", \"\")))\n",
    "            except:\n",
    "                continue\n",
    "    return \"\"\n",
    "\n",
    "print(\"Quick test functions defined!\")\n",
    "print(\"Note: For best results, restart runtime and use the post-restart evaluation cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "run_eval"
   },
   "outputs": [],
   "source": "## Note: Google Drive Integration\n\nYour model and checkpoints are **automatically saved to Google Drive** at:\n```\n/content/drive/MyDrive/Colab Notebooks/PRM-Math/checkpoints/\n```\n\nFeatures:\n- **Checkpoints**: Saved every 100 steps during training\n- **Resume Training**: Automatically detected and resumed on next run\n- **Merged Model**: Saved after training completes\n- **Persistent**: Survives runtime disconnects and restarts"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "drive_header"
   },
   "source": "# Utility: List saved checkpoints and models\nimport os\n\nDRIVE_PROJECT_PATH = \"/content/drive/MyDrive/Colab Notebooks/PRM-Math\"\ncheckpoint_dir = f\"{DRIVE_PROJECT_PATH}/checkpoints\"\n\nprint(\"Saved files in Google Drive:\")\nprint(\"=\"*50)\n\nif os.path.exists(checkpoint_dir):\n    for item in sorted(os.listdir(checkpoint_dir)):\n        item_path = os.path.join(checkpoint_dir, item)\n        if os.path.isdir(item_path):\n            # Get size\n            size = sum(os.path.getsize(os.path.join(item_path, f)) \n                      for f in os.listdir(item_path) if os.path.isfile(os.path.join(item_path, f)))\n            print(f\"  \ud83d\udcc1 {item} ({size/1e9:.2f} GB)\")\n        else:\n            size = os.path.getsize(item_path)\n            print(f\"  \ud83d\udcc4 {item} ({size/1e6:.2f} MB)\")\nelse:\n    print(\"  No checkpoints found yet.\")\n\nprint(\"\\nTo clear old checkpoints (keep only merged model):\")\nprint(\"  !rm -rf '/content/drive/MyDrive/Colab Notebooks/PRM-Math/checkpoints/checkpoint-*'\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create destination directory\n",
    "drive_path = \"/content/drive/MyDrive/PRM-Math-Models\"\n",
    "!mkdir -p \"{drive_path}\"\n",
    "\n",
    "# Copy model\n",
    "print(f\"Copying model to {drive_path}...\")\n",
    "shutil.copytree(merged_model_path, f\"{drive_path}/merged_model\", dirs_exist_ok=True)\n",
    "\n",
    "print(\"Model saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Training a Process Reward Model (PRM)** using the Math-Shepherd dataset\n",
    "2. **Generative verification** where the model predicts \"+\" or \"-\" tokens\n",
    "3. **Best-of-N search** with step-wise scoring\n",
    "4. **Evaluation** on GSM8K benchmark\n",
    "\n",
    "### Important: Correct PRM Architecture\n",
    "- **BASE model** (Qwen-Math) \u2192 Generates solution candidates\n",
    "- **Fine-tuned PRM** \u2192 Scores/ranks the candidates\n",
    "- This requires **restarting runtime** after training to load both models cleanly\n",
    "\n",
    "### Recommended Workflow:\n",
    "1. Run cells 1-15 for training\n",
    "2. Save model (cell 15)\n",
    "3. **Restart runtime** (Runtime \u2192 Restart runtime)\n",
    "4. Run cells 20-23 for evaluation (these load models without Unsloth)\n",
    "\n",
    "### Hyperparameter Recommendations (L4 GPU, 24GB):\n",
    "| Setting | Quick Test | Good Results | Best Results |\n",
    "|---------|-----------|--------------|--------------|\n",
    "| `max_samples` | 5,000 | 15,000 | 30,000+ |\n",
    "| `num_train_epochs` | 1 | 2 | 2-3 |\n",
    "| `batch_size` | 8 | 8 | 8 |\n",
    "| `gradient_accumulation_steps` | 4 | 4 | 4 |\n",
    "| Estimated time | ~30 min | ~2-3 hours | ~6+ hours |\n",
    "\n",
    "### Next Steps:\n",
    "- Train with more data and epochs for better PRM\n",
    "- Experiment with different aggregation strategies (product, mean vs min)\n",
    "- Evaluate on MATH dataset for harder problems"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "008bced0cf5c45e8a86d9575372d6e1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02a63cc79e6e41f6ad77813763360a28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "051325ce4bf84d1495c84fa915f6412e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82a1b717b625443abe29af39247d7325",
      "max": 13500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5040371193b44ddb6218d5a0376280d",
      "value": 13500
     }
    },
    "0527f24176ab42d790e7105109ef8e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc77671a445044eab701fadd7a028981",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5a540b2ee84246baa0d5f58471258de0",
      "value": "\u20071.67M/?\u2007[00:00&lt;00:00,\u200775.5MB/s]"
     }
    },
    "07f635d56d9f40d5b4dfa5b41e418e5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0826a059e93d41f6bfa59e774b35fc0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b186234c00a74a2088fb7e96074d0cd1",
       "IPY_MODEL_28f844656d494a71851309e6d9ede971",
       "IPY_MODEL_705edc11f4304afdb2f8be883b0bbcb9"
      ],
      "layout": "IPY_MODEL_778ec019c31c4b7ba078811cdc7a3224"
     }
    },
    "08965a6842a14a5d9cedd1f91f32765b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af0c868720fe40a2900795917050954b",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_c6c06ee2cdea4d048c0718f982f73e59",
      "value": "Generating\u2007test\u2007split:\u2007100%"
     }
    },
    "0c14d08de8e641288a439f1cf3636e80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dd34920d0a449d1b32de0e4da9a9bf5",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_84508c33092044ccbaf138a80ed08b15",
      "value": "\u2007447k/?\u2007[00:00&lt;00:00,\u200728.8MB/s]"
     }
    },
    "0c8d77105e2740f5a509fd0821da87ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86fd00c7009a482ea291e19daa9e7983",
       "IPY_MODEL_33a6169a4c4e42bc9930660933a48424",
       "IPY_MODEL_97da26d3187f4683ba850cea6ce0f000"
      ],
      "layout": "IPY_MODEL_f847c5a7a22240d084a7a3d7ee633bda"
     }
    },
    "0d568da2ef4f45d1ad2c2390870639bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d758e03caaa42ed84ac279fb0dddc98",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_6e8842ba145b4201acd49634d00b716a",
      "value": "model.safetensors:\u2007100%"
     }
    },
    "0d758e03caaa42ed84ac279fb0dddc98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0db02d60fe354a889921ba239078b0b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a53f5fe3a07042fa8cf7a195e0dd60e3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_911ed424559c40009540e3668b8c68ba",
      "value": 1
     }
    },
    "0dd34920d0a449d1b32de0e4da9a9bf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1084ee12990c49419215fc020ae2b893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1165e8baa84e41519093e5d6957306d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11f7044cc9014182b07c59d7e02ffe9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fd8ce334a004be2a66af0cbf4248f55",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_ef5db529f1c44a5d981bc7d3e8912a14",
      "value": "test.jsonl:\u2007"
     }
    },
    "12a32595a43e4d90931f62294ca7defd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "13968d9e5c0141178b61b0791fda3944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14186acb1c4642598faaea25aba06b7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "153a8abe296243ceae4b24862a93d62f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07f635d56d9f40d5b4dfa5b41e418e5e",
      "max": 613,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74eeef45205c408395a739e11ba9d36b",
      "value": 613
     }
    },
    "17c29a5140d04975b721a309232c6ed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe6584b1e8474a61b29f2677508d94ec",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_14186acb1c4642598faaea25aba06b7c",
      "value": "\u2007613/613\u2007[00:00&lt;00:00,\u200776.3kB/s]"
     }
    },
    "192fb806959741298d9698389b75b6ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1bac97c71718446f8e030ac6fb1dc435": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c897a49bb934d2db5d79a7f89040c22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e78aa49bb0e40b68ad0b25b48e5438e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_469bd98623094b3bb81473e8e363cde5",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_c8f839a3bd664cfab1b94055b78090dc",
      "value": "tokenizer.json:\u2007"
     }
    },
    "1f43919678b741b7947b7c45de1eacbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f491d1e5f714518b3e45d93efff4401": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f4bec4c01b44c02aa0d3a6413d1491a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e230987a642e4f48b1c9d92232ddcf52",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_8b07f697596241d7a0a1e5044f7f39a6",
      "value": "\u20073.09G/3.09G\u2007[00:10&lt;00:00,\u2007212MB/s]"
     }
    },
    "20d52e704309459a9ffbe80f3e9ee207": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21421d5313de46feb571bbbdb92c91a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d31b6225af14914a4d1b4a0921a797f",
       "IPY_MODEL_ffa952b2dc1a4d4eb9bec3a03d83418d",
       "IPY_MODEL_23ef1c5a42094366b66f6b807e3b6d2c"
      ],
      "layout": "IPY_MODEL_6a60551fe0d44f4e8e288b6fcd2e8f0b"
     }
    },
    "239100f96fdb416eab16e6899edd84b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e78aa49bb0e40b68ad0b25b48e5438e",
       "IPY_MODEL_0db02d60fe354a889921ba239078b0b0",
       "IPY_MODEL_defb9657d1ae4956abe594c1014c1b45"
      ],
      "layout": "IPY_MODEL_23ef73a7638a4acca00dd278c5f28b8a"
     }
    },
    "23d56bc5a429447ebe228c511bb6367b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ef1c5a42094366b66f6b807e3b6d2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1084ee12990c49419215fc020ae2b893",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_32fdef866d314881b6449364f7eea3fc",
      "value": "\u20071.14G/1.14G\u2007[00:02&lt;00:00,\u2007825MB/s]"
     }
    },
    "23ef73a7638a4acca00dd278c5f28b8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "254cd26e88c04f6fb36ab9ed47cbdf35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "265fa99315d74861a7fcc0c0d9eb4213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88e636f6386b4175a66589e060b8af7e",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_6f6ecf4ed3cd410f956118e04e225009",
      "value": "added_tokens.json:\u2007100%"
     }
    },
    "27c41d6ca8ef438ebb928eb2c1047879": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f844656d494a71851309e6d9ede971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_911a3a6b9aea4ce58431a7fc7d17d4de",
      "max": 412,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a6fbf9761a0497faa0fdc3f783bbe05",
      "value": 412
     }
    },
    "2eb89fae30ba45b3a350f476aec79904": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f0bae426e9f45f794828f41e1e43713": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30669924477442aab4a0a0521e1038c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f7395d38bcf417fbb6cacd480369912",
      "max": 444655,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02a63cc79e6e41f6ad77813763360a28",
      "value": 444655
     }
    },
    "319c88d1506545ceb3d5d7f04482da43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32ccbc7fd996407dad26506f624cbf7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc28eb3401df4f8a98fa1679f631b0c5",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_8ed0fd2512634b9e9a8add62baf536aa",
      "value": "\u2007632/632\u2007[00:00&lt;00:00,\u200782.6kB/s]"
     }
    },
    "32fdef866d314881b6449364f7eea3fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "330ec35c7c1346af9885a8beb8ebdece": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33a6169a4c4e42bc9930660933a48424": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae771ba3cc2940dca6981f355e377ff0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12a32595a43e4d90931f62294ca7defd",
      "value": 1
     }
    },
    "376e2d1621bc492893032eaea69defd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bc092665828468d8fa06c0188a67732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c277e5b557d04774b1c288b749f2a563",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_45659833a4894e6c9f0652c69917fd82",
      "value": "special_tokens_map.json:\u2007100%"
     }
    },
    "3cf8168e73084be8b66e8b2f9d727710": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e363047a9d040eebfcdb47704bbd8d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f7395d38bcf417fbb6cacd480369912": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fe87f5bf39240969bbd491957549b0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4012d18f19f548a3b64b26e72b32a332": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "420190dc4dd545f5a0c2f56a79b0b72a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_008bced0cf5c45e8a86d9575372d6e1c",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_496a7f680f5742dd90648c6a227ceb22",
      "value": "\u2007761/761\u2007[00:00&lt;00:00,\u2007104kB/s]"
     }
    },
    "432ddd9532e5486db253d3db8a770b68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca07e786abca4a8e9a2c01ec09f9e6a3",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_bca9046b2be04c369ce271b6ce8f765b",
      "value": "generation_config.json:\u2007100%"
     }
    },
    "43445d194e97489ba125f46a54d45b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a20ad5a6ffe481bad79ba267dc0b01a",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_3e363047a9d040eebfcdb47704bbd8d3",
      "value": "\u20071500/1500\u2007[00:04&lt;00:00,\u2007565.03\u2007examples/s]"
     }
    },
    "45659833a4894e6c9f0652c69917fd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "469bd98623094b3bb81473e8e363cde5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46d1b2948aa14d999653f2803da64da2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "470df68d008249368f881258c4344018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_432ddd9532e5486db253d3db8a770b68",
       "IPY_MODEL_b5adb245ca2a4839a0d84afd4e98f2b7",
       "IPY_MODEL_c4ec85ca897745888224a8fc6eaa3b5a"
      ],
      "layout": "IPY_MODEL_c5168ec7996b4e208a3393284c1e7436"
     }
    },
    "496a7f680f5742dd90648c6a227ceb22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a12e75d19ba42028c1fa45c67a0bce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_621965104b6c456d9b488ed0479330f8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3cf8168e73084be8b66e8b2f9d727710",
      "value": 1
     }
    },
    "4a20ad5a6ffe481bad79ba267dc0b01a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a6fbf9761a0497faa0fdc3f783bbe05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c1babb43387427f87de54567301ab14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_08965a6842a14a5d9cedd1f91f32765b",
       "IPY_MODEL_8ade6c47b996408cafd13f600d3d593a",
       "IPY_MODEL_d461eae934a240a0bffeb0be448f9143"
      ],
      "layout": "IPY_MODEL_595fd4461df44cd1b16c0e016b786890"
     }
    },
    "4d31b6225af14914a4d1b4a0921a797f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fb93e1f4fc5482f8e9a60d1b24a3e43",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_515aa26bbd9b420ea98bba7978162d1d",
      "value": "model.safetensors:\u2007100%"
     }
    },
    "4da9effb5db54668b5dc2b67573767d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e5445733c6e4fa99e06d7fefc35b017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d58e5f71e895482f8bf99e03e9b7a489",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_dfb161b4d6824280a9c01631b2896d6a",
      "value": "merges.txt:\u2007"
     }
    },
    "4fa458db586048eeb4ae1d0978632ea1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "515aa26bbd9b420ea98bba7978162d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5388126c6d7640619dfcb49dd9c321f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5470afc5235645008f61a029550afaf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "550e85f8021e4b168bbe8a0856154720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e589849d5ac84675acd25aedcfadf56b",
       "IPY_MODEL_ee6a7b4a2c4b4b14a6ccefeaac814c46",
       "IPY_MODEL_43445d194e97489ba125f46a54d45b3d"
      ],
      "layout": "IPY_MODEL_cf4cbe0252af48069a770a0735b66b5f"
     }
    },
    "5907dbda3ca94a399455aabb0f1a2ff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5921a0afc2e64509af04131151929d32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6836ed15891543f6840f452c15811cc2",
       "IPY_MODEL_970d6cccfd9446fa8a518cf71250b21b",
       "IPY_MODEL_d1155c55e42240cea85df02a949a84f1"
      ],
      "layout": "IPY_MODEL_f16bc2510d664a5697c76a61472201bf"
     }
    },
    "595fd4461df44cd1b16c0e016b786890": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a540b2ee84246baa0d5f58471258de0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c405fea068641e68f749628b3d62a5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fff16ff3ce04db8a115ae67aa85cd5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60c7d67218084e2e8f9781625546c0e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd95bbf703184a95a7b3bd77815a8bdd",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_756ceab403c048f18587a491d878016f",
      "value": "\u200713500/13500\u2007[00:04&lt;00:00,\u20074780.04\u2007examples/s]"
     }
    },
    "61a4b3dc1e694aa38e88c9e406edd666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "621965104b6c456d9b488ed0479330f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "62589bee47f642d2a94a77a18e7598e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "633c8fcd3f2d4e4390bb1e6d59e78a55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63a8725c4148435cb9cc828bc7159c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_744b86adf7d2484dbc53dc112ba02c09",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5470afc5235645008f61a029550afaf5",
      "value": "\u20077.52k/?\u2007[00:00&lt;00:00,\u2007932kB/s]"
     }
    },
    "6836ed15891543f6840f452c15811cc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27c41d6ca8ef438ebb928eb2c1047879",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_a34fecb1301543178113856bd391fe27",
      "value": "math-shepherd.jsonl:\u2007100%"
     }
    },
    "686b0c2e41f543efb1ba0db1f7cc7645": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69ff86bcae0a4e788690a3c3c6c36337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a60551fe0d44f4e8e288b6fcd2e8f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aafc9587caf41bba39d9a9467d2ab65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dcccf8c5aac4adcba7b81c2c4b531ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "6e38b38e3c384bc5abbfbb55d26856ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dcccf8c5aac4adcba7b81c2c4b531ce",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f18fe8558a6a4da188c7b119ce396ea9",
      "value": 1
     }
    },
    "6e8842ba145b4201acd49634d00b716a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f6ecf4ed3cd410f956118e04e225009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fd8ce334a004be2a66af0cbf4248f55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "705edc11f4304afdb2f8be883b0bbcb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77370177a5f74d30abdd6bfe5b838a31",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_dadb6e2ea5394eacbe74f98901ab663e",
      "value": "\u2007412/412\u2007[00:00&lt;00:00,\u200752.5kB/s]"
     }
    },
    "70744076965f47df9a4dde198dbdc998": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d568da2ef4f45d1ad2c2390870639bc",
       "IPY_MODEL_a1af39e8754440afb784e6ed589fdc88",
       "IPY_MODEL_1f4bec4c01b44c02aa0d3a6413d1491a"
      ],
      "layout": "IPY_MODEL_686b0c2e41f543efb1ba0db1f7cc7645"
     }
    },
    "72fcbc845f9243b0b0900d087189e534": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_11f7044cc9014182b07c59d7e02ffe9f",
       "IPY_MODEL_4a12e75d19ba42028c1fa45c67a0bce8",
       "IPY_MODEL_0c14d08de8e641288a439f1cf3636e80"
      ],
      "layout": "IPY_MODEL_9d0ba508edff49c9b57456adc37ac6ed"
     }
    },
    "744b86adf7d2484dbc53dc112ba02c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74eeef45205c408395a739e11ba9d36b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "756ceab403c048f18587a491d878016f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77370177a5f74d30abdd6bfe5b838a31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "778ec019c31c4b7ba078811cdc7a3224": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7876f915aea84c6d8087a3aa3af31a05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b96cb5199804972aefa1d510aeddfe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f5093dcadf447caa4c5cd5f6ea6d64e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aeeccfd6beae4e69b1e0cce4fab2b196",
       "IPY_MODEL_051325ce4bf84d1495c84fa915f6412e",
       "IPY_MODEL_60c7d67218084e2e8f9781625546c0e9"
      ],
      "layout": "IPY_MODEL_9efdc30d7ddb41ef84bbcd29878254ac"
     }
    },
    "7fb93e1f4fc5482f8e9a60d1b24a3e43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82a1b717b625443abe29af39247d7325": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "836f44328fe641c1904d061d8b169630": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a284cadba47b4bfaa036cc9e23dff744",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_fb36005415af467b835ba243f21ad820",
      "value": "Generating\u2007train\u2007split:\u2007100%"
     }
    },
    "84508c33092044ccbaf138a80ed08b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86fd00c7009a482ea291e19daa9e7983": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbb07acc3a43421687514e459360ad37",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5388126c6d7640619dfcb49dd9c321f8",
      "value": "vocab.json:\u2007"
     }
    },
    "87cf338bd8fd423494f1f9cd3ed21a84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c03a6f3024684cadaaf71169888772a8",
       "IPY_MODEL_ef95aba74c4643ea9245f4e52141ffbd",
       "IPY_MODEL_a1523c3b8f9f4c54a59c1644a1f9e9c0"
      ],
      "layout": "IPY_MODEL_20d52e704309459a9ffbe80f3e9ee207"
     }
    },
    "886b5e7e8b9b4276bd268523763ad21b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddceca5cc97744329ebfd440415cff8b",
      "max": 761,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_192fb806959741298d9698389b75b6ba",
      "value": 761
     }
    },
    "887922900a5d43e3bacf76e2bac5ed07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_836f44328fe641c1904d061d8b169630",
       "IPY_MODEL_30669924477442aab4a0a0521e1038c1",
       "IPY_MODEL_a710783e706948c7bcefbb929ab402c1"
      ],
      "layout": "IPY_MODEL_2f0bae426e9f45f794828f41e1e43713"
     }
    },
    "88e636f6386b4175a66589e060b8af7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ac85a27544549deb4cd67e9f14358fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ade6c47b996408cafd13f600d3d593a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c897a49bb934d2db5d79a7f89040c22",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62589bee47f642d2a94a77a18e7598e3",
      "value": 500
     }
    },
    "8b07f697596241d7a0a1e5044f7f39a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d10b0f4287148c997a5861bfc022fa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ed0fd2512634b9e9a8add62baf536aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f657afefce648ea81b0ff1900c89f73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "911a3a6b9aea4ce58431a7fc7d17d4de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "911ed424559c40009540e3668b8c68ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92c875504ff74899944a8e5d666b103b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bc092665828468d8fa06c0188a67732",
       "IPY_MODEL_153a8abe296243ceae4b24862a93d62f",
       "IPY_MODEL_17c29a5140d04975b721a309232c6ed9"
      ],
      "layout": "IPY_MODEL_69ff86bcae0a4e788690a3c3c6c36337"
     }
    },
    "95282053a87f492898c6c7252d1f1ada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b94a65d13e841259d59931e5c6515ab",
       "IPY_MODEL_886b5e7e8b9b4276bd268523763ad21b",
       "IPY_MODEL_420190dc4dd545f5a0c2f56a79b0b72a"
      ],
      "layout": "IPY_MODEL_330ec35c7c1346af9885a8beb8ebdece"
     }
    },
    "970d6cccfd9446fa8a518cf71250b21b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23d56bc5a429447ebe228c511bb6367b",
      "max": 793059998,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5601c851a80467391ffd7073e9826a2",
      "value": 793059998
     }
    },
    "97da26d3187f4683ba850cea6ce0f000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f491d1e5f714518b3e45d93efff4401",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_61a4b3dc1e694aa38e88c9e406edd666",
      "value": "\u20072.78M/?\u2007[00:00&lt;00:00,\u200745.7MB/s]"
     }
    },
    "98bc502171994974b667740779cdb709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b94a65d13e841259d59931e5c6515ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad0163b617aa422cb0c5be6bb9ccd480",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_98bc502171994974b667740779cdb709",
      "value": "config.json:\u2007100%"
     }
    },
    "9d0ba508edff49c9b57456adc37ac6ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9efdc30d7ddb41ef84bbcd29878254ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1523c3b8f9f4c54a59c1644a1f9e9c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ac85a27544549deb4cd67e9f14358fa",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_ef7e4dff023d44ddbfb7cf9dcd8592cd",
      "value": "\u20072.65k/?\u2007[00:00&lt;00:00,\u2007240kB/s]"
     }
    },
    "a1af39e8754440afb784e6ed589fdc88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6aafc9587caf41bba39d9a9467d2ab65",
      "max": 3087467144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f43919678b741b7947b7c45de1eacbd",
      "value": 3087467144
     }
    },
    "a284cadba47b4bfaa036cc9e23dff744": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2de85977af644e0ac580ec25f6a160a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a34fecb1301543178113856bd391fe27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a53f5fe3a07042fa8cf7a195e0dd60e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a5a3fe77bc434ce5b0c2ed2e24465359": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a710783e706948c7bcefbb929ab402c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4740d9cfc6e443eb8b0a014de778192",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_4da9effb5db54668b5dc2b67573767d6",
      "value": "\u2007444655/444655\u2007[00:01&lt;00:00,\u2007201652.55\u2007examples/s]"
     }
    },
    "a8324ce1713a40cd9ad046af10c13115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a83eaa27285647d18afd4cdd43ef7f9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad0163b617aa422cb0c5be6bb9ccd480": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae771ba3cc2940dca6981f355e377ff0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "aeeccfd6beae4e69b1e0cce4fab2b196": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c405fea068641e68f749628b3d62a5e",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5fff16ff3ce04db8a115ae67aa85cd5b",
      "value": "Unsloth:\u2007Tokenizing\u2007[&quot;text&quot;]\u2007(num_proc=16):\u2007100%"
     }
    },
    "af0c868720fe40a2900795917050954b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b186234c00a74a2088fb7e96074d0cd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5a3fe77bc434ce5b0c2ed2e24465359",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_cd7f0a52c6fe432488f1c1d285ea7c1d",
      "value": "README.md:\u2007100%"
     }
    },
    "b2190d332aea4978a63ba88527e3752e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5adb245ca2a4839a0d84afd4e98f2b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_254cd26e88c04f6fb36ab9ed47cbdf35",
      "max": 161,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec5955a2a6bf4197a3cb585314579493",
      "value": 161
     }
    },
    "bca9046b2be04c369ce271b6ce8f765b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf3ebe52f38e460dae32b90f6024f534": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_265fa99315d74861a7fcc0c0d9eb4213",
       "IPY_MODEL_f9c2736113ce4023a05d95c7a3303048",
       "IPY_MODEL_32ccbc7fd996407dad26506f624cbf7a"
      ],
      "layout": "IPY_MODEL_376e2d1621bc492893032eaea69defd5"
     }
    },
    "c03a6f3024684cadaaf71169888772a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13968d9e5c0141178b61b0791fda3944",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_fcf91a6b8e6f434e907c6af76df71777",
      "value": "README.md:\u2007"
     }
    },
    "c277e5b557d04774b1c288b749f2a563": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c34e999df3de46daa12498efc705b1e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4012d18f19f548a3b64b26e72b32a332",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_319c88d1506545ceb3d5d7f04482da43",
      "value": "tokenizer_config.json:\u2007"
     }
    },
    "c4ec85ca897745888224a8fc6eaa3b5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2190d332aea4978a63ba88527e3752e",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_a2de85977af644e0ac580ec25f6a160a",
      "value": "\u2007161/161\u2007[00:00&lt;00:00,\u200720.5kB/s]"
     }
    },
    "c5168ec7996b4e208a3393284c1e7436": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6c06ee2cdea4d048c0718f982f73e59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7ba0df54bb84784a0f92b74c93e5ad4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8f839a3bd664cfab1b94055b78090dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca07e786abca4a8e9a2c01ec09f9e6a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbb07acc3a43421687514e459360ad37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd7f0a52c6fe432488f1c1d285ea7c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd95bbf703184a95a7b3bd77815a8bdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf4cbe0252af48069a770a0735b66b5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1155c55e42240cea85df02a949a84f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_633c8fcd3f2d4e4390bb1e6d59e78a55",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5907dbda3ca94a399455aabb0f1a2ff9",
      "value": "\u2007793M/793M\u2007[00:01&lt;00:00,\u2007653MB/s]"
     }
    },
    "d461eae934a240a0bffeb0be448f9143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6af3b8bf9d44b6f86494a3e4e385c04",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_8f657afefce648ea81b0ff1900c89f73",
      "value": "\u2007500/500\u2007[00:00&lt;00:00,\u200729931.95\u2007examples/s]"
     }
    },
    "d5040371193b44ddb6218d5a0376280d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5601c851a80467391ffd7073e9826a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d58e5f71e895482f8bf99e03e9b7a489": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7cabf5f4f224147a5e16bab2a64e795": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "dadb6e2ea5394eacbe74f98901ab663e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc77671a445044eab701fadd7a028981": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddceca5cc97744329ebfd440415cff8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de5761c4afe642bb9a5cae7ee26effdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c34e999df3de46daa12498efc705b1e2",
       "IPY_MODEL_6e38b38e3c384bc5abbfbb55d26856ca",
       "IPY_MODEL_63a8725c4148435cb9cc828bc7159c69"
      ],
      "layout": "IPY_MODEL_1bac97c71718446f8e030ac6fb1dc435"
     }
    },
    "defb9657d1ae4956abe594c1014c1b45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2eb89fae30ba45b3a350f476aec79904",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_7876f915aea84c6d8087a3aa3af31a05",
      "value": "\u20077.03M/?\u2007[00:00&lt;00:00,\u2007126MB/s]"
     }
    },
    "df2af4741c374ff5819d358246dfe4fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfb161b4d6824280a9c01631b2896d6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e108630cdaf046d9b6a59c3096d748e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "e230987a642e4f48b1c9d92232ddcf52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4740d9cfc6e443eb8b0a014de778192": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e589849d5ac84675acd25aedcfadf56b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df2af4741c374ff5819d358246dfe4fe",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_ee4d7b2694c047e49550af84992095e4",
      "value": "Unsloth:\u2007Tokenizing\u2007[&quot;text&quot;]\u2007(num_proc=16):\u2007100%"
     }
    },
    "ec5955a2a6bf4197a3cb585314579493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee4d7b2694c047e49550af84992095e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee6a7b4a2c4b4b14a6ccefeaac814c46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b96cb5199804972aefa1d510aeddfe5",
      "max": 1500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a83eaa27285647d18afd4cdd43ef7f9d",
      "value": 1500
     }
    },
    "ef5db529f1c44a5d981bc7d3e8912a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef7e4dff023d44ddbfb7cf9dcd8592cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef95aba74c4643ea9245f4e52141ffbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e108630cdaf046d9b6a59c3096d748e0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d10b0f4287148c997a5861bfc022fa9",
      "value": 1
     }
    },
    "f16bc2510d664a5697c76a61472201bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f18fe8558a6a4da188c7b119ce396ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f64f6ee19fd24ea3b71f90e2174973f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e5445733c6e4fa99e06d7fefc35b017",
       "IPY_MODEL_f9193f5e203c406ba0aea3598555cd2c",
       "IPY_MODEL_0527f24176ab42d790e7105109ef8e32"
      ],
      "layout": "IPY_MODEL_4fa458db586048eeb4ae1d0978632ea1"
     }
    },
    "f6af3b8bf9d44b6f86494a3e4e385c04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f847c5a7a22240d084a7a3d7ee633bda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9193f5e203c406ba0aea3598555cd2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7cabf5f4f224147a5e16bab2a64e795",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46d1b2948aa14d999653f2803da64da2",
      "value": 1
     }
    },
    "f9c2736113ce4023a05d95c7a3303048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7ba0df54bb84784a0f92b74c93e5ad4",
      "max": 632,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fe87f5bf39240969bbd491957549b0b",
      "value": 632
     }
    },
    "fb36005415af467b835ba243f21ad820": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc28eb3401df4f8a98fa1679f631b0c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcf91a6b8e6f434e907c6af76df71777": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe6584b1e8474a61b29f2677508d94ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffa952b2dc1a4d4eb9bec3a03d83418d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1165e8baa84e41519093e5d6957306d7",
      "max": 1143327678,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8324ce1713a40cd9ad046af10c13115",
      "value": 1143327678
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}